{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Task* - Domain Adaptation for Semantic Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Develop a methodology which optimizes a neural network for semantic image segmentation trained on public datasets with regard to its predictive performance on data affected by domain shift.\n",
    "\n",
    "- [Background and Motivation](#background-and-motivation)\n",
    "- [Task](#task)\n",
    "- [Required Tools and Data](#required-tools-and-data)\n",
    "- [Hints](#Hints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Motivation\n",
    "\n",
    "The main purpose of supervised learning is to repeatedly serve a training algorithm with input-label-pairs (samples), s.t. the optimized model not only performs well on the training data, but also generalizes well to unseen data (validation/test data). Generalizing to unseen data that is in principle similar to training data seems easier than generalizing to unseen and very dissimilar data. One example is that a model, which is trained on image data from Aachen on a sunny day, will most likely perform better on other Aachen images of a sunny day than on New York images on a rainy day. Ideally, one would always be able to train models on training data similar to the target domain of where the model is supposed be used.\n",
    "\n",
    "The collection and labeling of suitable datasets for a particular supervised learning task, however, is usually associated with a lot of (manual) effort. In the case of image segmentation, creating a new dataset requires the oftentimes manual annotation of every single image in the dataset by associating every pixel with a particular semantic class. One example of an input image for semantic image segmentation and a corresponding semantic segmentation label is shown below.\n",
    "\n",
    "![](./assets/semantic-image-segmentation.png)\n",
    "\n",
    "Considering the labeling effort, it is desirable to make the most use out of publicly available datasets. Careful application of data augmentation, domain adaptation, and hyperparameter tuning techniques has the potential to improve generalization capabilities of trained models, allowing them to perform better on new domains (e.g., different sensor setup, different environment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "The task is to develop a methodology which optimizes a neural network for semantic image segmentation trained on public datasets with regard to its predictive performance on data affected by domain shift.\n",
    "\n",
    "### Subtasks\n",
    "\n",
    "> ***Note:*** *The subtasks listed below do not have to be followed strictly. They serve the purpose of guiding you along your own research for this topic.*\n",
    "\n",
    "1. Search for and choose **two** publicly available datasets for semantic image segmentation related to driving (e.g. *Cityscapes*).\n",
    "1. Research augmentation and domain adaptation techniques for semantic image segmentation, such as ...\n",
    "   - image flipping\n",
    "   - modification of image brightness, contrast, etc.\n",
    "   - merging of classes (e.g., if training dataset distinguishes between cars and buses, but target domain only cares about vehicles in general)\n",
    "   - use of some (labeled) target domain samples in training dataset, possibly given extra weight as compared to standard samples\n",
    "   - ...\n",
    "1. Research training techniques to improve generalization, such as ...\n",
    "   - dropout\n",
    "   - L1/L2 regularization\n",
    "   - ...\n",
    "1. Implement a TensorFlow data pipeline, possibly including online data augmentation.\n",
    "1. Implement a TensorFlow model for semantic image segmentation.\n",
    "1. Train models on both selected public datasets and evaluate their performance on each other (suggested metric: *Mean IoU*).\n",
    "   1. Train on dataset 1 training data, evaluate on dataset 2 validation data, evaluate on ika's validation data.\n",
    "   1. Train on dataset 2 training data, evaluate on dataset 1 validation data, evaluate on ika's validation data.\n",
    "   1. Train on dataset 1+2 training data combined, evaluate on dataset 1 validation data, evaluate on dataset 2 validation data, evaluate on ika's validation data.\n",
    "1. Iterate on the trainings with different augmentation, domain adaptation, generalization techniques, and other hyperparameters in order to optimize generalization capabilities of the trained models, especially with regard to ika's validation dataset.\n",
    "1. Document your research, developed approach, and evaluations in a Jupyter notebook report. Explain and reproduce individual parts of your implemented functions with exemplary data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Tools and Data\n",
    "\n",
    "### Tools\n",
    "\n",
    "- TensorFlow\n",
    "- Image Segmentation Training Pipeline & Model *(see [ACDC Exercise: Semantic Image Segmentation](https://github.com/ika-rwth-aachen/acdc-notebooks/blob/main/section_2_sensor_data_processing/1_semantic_image_segmentation.ipynb))*\n",
    "\n",
    "### Data\n",
    "\n",
    "- [ika's validation dataset](data/ika-dataset/)\n",
    "- *(to be found)* two publicly available datasets for semantic image segmentation related to driving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "### Relevant ACDC Sections\n",
    "\n",
    "- **Sensor Data Processing Algorithms**\n",
    "  - Image Segmentation\n",
    "\n",
    "### TFDS Datasets\n",
    "\n",
    "[TensorFlow Datasets](https://www.tensorflow.org/datasets) is a collection of datasets ready-to-use with TensorFlow. It may already contain datasets interesting for semantic image segmentation and thus save you from worrying about parsing data files from disk. All TFDS datasets are exposed as [`tf.data.Dataets`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset), ready to be passed to [`model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).\n",
    "\n",
    "The example below shows how easy it is to load a TFDS dataset, in this case the famous [MNIST dataset](https://www.tensorflow.org/datasets/catalog/mnist). Note that this dataset is not related to semantic image segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.10.0 in /opt/conda/lib/python3.9/site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorflow-datasets==4.4.0 in /opt/conda/lib/python3.9/site-packages (4.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (3.7.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (4.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.22.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (22.9.24)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (2.10.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (0.27.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.49.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (14.0.6)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.14.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (2.0.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (3.19.6)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets==4.4.0) (0.3.5.1)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets==4.4.0) (1.10.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets==4.4.0) (4.62.1)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets==4.4.0) (0.18.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets==4.4.0) (2.26.0)\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets==4.4.0) (2.3)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets==4.4.0) (21.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.37.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0) (2021.10.8)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.6.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->tensorflow==2.10.0) (2.4.7)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow-metadata->tensorflow-datasets==4.4.0) (1.56.4)\n"
     ]
    }
   ],
   "source": [
    "# install required Python packages via pip\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install \\\n",
    "    tensorflow==2.10.0 \\\n",
    "    tensorflow-datasets==4.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 12:01:34.618958: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-13 12:01:34.751233: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-13 12:01:35.240028: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/targets/x86_64-linux/lib:/usr/local//usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-13 12:01:35.240078: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/targets/x86_64-linux/lib:/usr/local//usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-13 12:01:35.240084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-13 12:01:36.129263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-13 12:01:36.133901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-13 12:01:36.134605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-13 12:01:36.135589: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-13 12:01:36.137462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-13 12:01:36.138164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-13 12:01:36.138840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-13 12:01:36.519141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-13 12:01:36.519838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-13 12:01:36.520485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-13 12:01:36.521115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21603 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2023-01-13 12:01:36.796654: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TFDS MNIST dataset contains three different splits of data:\n",
      "{'test': <PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>, 'train': <PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>}\n",
      "The dataset has two features, 'image' and 'label'. Here is one sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b0d21\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b0d21_level0_col0\" class=\"col_heading level0 col0\" >image</th>\n",
       "      <th id=\"T_b0d21_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b0d21_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b0d21_row0_col0\" class=\"data row0 col0\" >[[[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [ 84]\n",
       "  [254]\n",
       "  [101]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [174]\n",
       "  [253]\n",
       "  [119]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [ 31]\n",
       "  [247]\n",
       "  [202]\n",
       "  [ 29]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  1]\n",
       "  [  1]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [141]\n",
       "  [253]\n",
       "  [168]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [ 66]\n",
       "  [208]\n",
       "  [ 56]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [186]\n",
       "  [253]\n",
       "  [120]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [ 57]\n",
       "  [253]\n",
       "  [119]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [ 28]\n",
       "  [249]\n",
       "  [240]\n",
       "  [ 25]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [ 34]\n",
       "  [253]\n",
       "  [119]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [109]\n",
       "  [254]\n",
       "  [197]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [ 53]\n",
       "  [253]\n",
       "  [119]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [135]\n",
       "  [254]\n",
       "  [133]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [133]\n",
       "  [254]\n",
       "  [119]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [ 27]\n",
       "  [240]\n",
       "  [255]\n",
       "  [ 35]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  7]\n",
       "  [235]\n",
       "  [253]\n",
       "  [208]\n",
       "  [151]\n",
       "  [169]\n",
       "  [215]\n",
       "  [253]\n",
       "  [206]\n",
       "  [  2]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [ 97]\n",
       "  [253]\n",
       "  [253]\n",
       "  [253]\n",
       "  [254]\n",
       "  [253]\n",
       "  [253]\n",
       "  [253]\n",
       "  [ 86]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [150]\n",
       "  [244]\n",
       "  [145]\n",
       "  [119]\n",
       "  [101]\n",
       "  [ 82]\n",
       "  [253]\n",
       "  [253]\n",
       "  [ 14]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [ 84]\n",
       "  [254]\n",
       "  [172]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [174]\n",
       "  [253]\n",
       "  [119]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [237]\n",
       "  [252]\n",
       "  [ 56]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [ 50]\n",
       "  [241]\n",
       "  [182]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [187]\n",
       "  [254]\n",
       "  [249]\n",
       "  [105]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [186]\n",
       "  [253]\n",
       "  [206]\n",
       "  [ 21]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [227]\n",
       "  [242]\n",
       "  [ 32]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [236]\n",
       "  [219]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]\n",
       "\n",
       " [[  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]\n",
       "  [  0]]]</td>\n",
       "      <td id=\"T_b0d21_row0_col1\" class=\"data row0 col1\" >4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load MNIST\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "ds = tfds.load(\"mnist\")\n",
    "print(\"The TFDS MNIST dataset contains three different splits of data:\")\n",
    "print(ds)\n",
    "print(\"The dataset has two features, 'image' and 'label'. Here is one sample:\")\n",
    "tfds.as_dataframe(ds[\"train\"].take(1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f35c820e40155ce3a3d6b6baab4aa8cb626eff9596fe63e71a966e5e0dc1513e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
