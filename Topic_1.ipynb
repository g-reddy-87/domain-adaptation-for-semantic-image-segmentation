{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/header-logo.png)\n",
    "## *Semantic Image Segmentation*\n",
    "\n",
    "**Automated and Connected Driving Challenges - Research Project - 09/2024**\n",
    "\n",
    "**Research Topic 1: Domain Adaptation for Semantic Image Segmentation**\n",
    "\n",
    "\n",
    "| Author | Mail | Matriculation\n",
    "| --- | --- | ---\n",
    "| **Gaurav Gidnahalli Anil Reddy** | gaurav.gidnahalli.anil.reddy@rwth-aachen.de / gauravgreddy@gmail.com| 442090\n",
    "| **Sidhant Konwar Roy** | sidhant.roy@rwth-aachen.de / sidhantkr9@gmail.com | 441084\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INSTALLATION OF PYTHON DEPENDENCIES ==========================\n",
    "\n",
    "!pip3 install -r Requirements.txt\n",
    "import sys\n",
    "\n",
    "# --- installation via pip -----------------------------------------\n",
    "\n",
    "# # install packages via pip (version numbers should be included to guarantee reproducibility)\n",
    "# !{sys.executable} -m pip install \\\n",
    "#     jupyter \\\n",
    "#     tensorflow\\\n",
    "#     matplotlib\\\n",
    "#     numpy \\\n",
    "#     opencv-python \\\n",
    "#     tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, MaxPooling2D, BatchNormalization, Dropout, Activation, Concatenate, RandomRotation\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "\n",
    "from segmentation_utils.metrics import SparseMeanIoU\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "import glob, sys, os, time\n",
    "import numpy as npy\n",
    "import random\n",
    "import matplotlib.pyplot as plot\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "random.seed(random.randint(0, 150))\n",
    "\n",
    "%matplotlib inline\n",
    "plot.rcParams['figure.figsize'] = (15, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are user-defined functions for downloading and extracting zip files from Google Drive to make it easier for the reader to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from ChatGPT\n",
    "import gdown\n",
    "import zipfile, os\n",
    "\n",
    "def download_file_from_google_drive(file_id, save_path):\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    gdown.download(url, save_path, quiet=False)\n",
    "    print(f\"File downloaded successfully and saved to {save_path}\")\n",
    "\n",
    "def unzip_file(zip_file_path, extract_to_folder):\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(extract_to_folder):\n",
    "        os.makedirs(extract_to_folder)\n",
    "\n",
    "    # Unzip the file\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to_folder)\n",
    "            print(f\"Files extracted successfully to {extract_to_folder}\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"Error: The file is not a valid zip file or it is corrupted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from ChatGPT\n",
    "\n",
    "file_id = '1Z_yZWpYdrnc0n6hefwD__9plos7H5fTs' # https://drive.google.com/file/d/1Z_yZWpYdrnc0n6hefwD__9plos7H5fTs/view?usp=drive_link\n",
    "save_folder = os.getcwd()\n",
    "save_path = os.path.join(save_folder, 'segmentation_utils.zip') \n",
    "extract_to_folder = os.path.join(save_folder, '')\n",
    "\n",
    "# Ensure the save folder exists\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    # Download the file\n",
    "    download_file_from_google_drive(file_id, save_path)\n",
    "\n",
    "    # Unzip the downloaded file\n",
    "    unzip_file(save_path, extract_to_folder)\n",
    "\n",
    "else:\n",
    "    print(\"File already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Downloads\n",
    "\n",
    "We have chosen the [KITTI](https://s3.eu-central-1.amazonaws.com/avg-kitti/data_semantics.zip) [[1]](https://www.cvlibs.net/publications/Alhaija2018IJCV.pdf) and CityScapes ([Image](https://www.cityscapes-dataset.com/file-handling/?packageID=3) and [Label](https://www.cityscapes-dataset.com/file-handling/?packageID=1)) [[2]](https://www.cityscapes-dataset.com/wordpress/wp-content/papercite-data/pdf/cordts2016cityscapes.pdf) datasets for the following research. A dataset from IKA is also used for evaluation. \n",
    "\n",
    "To manually download the datasets download and unzip the contents in a new folder 'datasets' located in the same folder as this jupyter notebook. To automate this process, please run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir datasets\n",
    "\n",
    "#KITTI\n",
    "\n",
    "file_id = '1noeCGWhE0S_3V4b-N9fCW89ppK1cgDnG' # https://drive.google.com/file/d/1noeCGWhE0S_3V4b-N9fCW89ppK1cgDnG/view?usp=sharing\n",
    "save_folder = os.getcwd()+'/datasets'\n",
    "save_path = os.path.join(save_folder, 'data_semantics.zip')\n",
    "extract_to_folder = os.path.join(save_folder, 'KITTI_Dataset')\n",
    "\n",
    "# Ensure the save folder exists\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    # Download the file\n",
    "    download_file_from_google_drive(file_id, save_path)\n",
    "\n",
    "    # Unzip the downloaded file\n",
    "    unzip_file(save_path, extract_to_folder)\n",
    "\n",
    "else:\n",
    "    print(\"File already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CityScapes Labels\n",
    "\n",
    "file_id = '1WErVByw6CxhFxYHdmQv3qphPHTFXeB-X' # https://drive.google.com/file/d/1WErVByw6CxhFxYHdmQv3qphPHTFXeB-X/view?usp=drive_link\n",
    "save_folder = os.getcwd()+'/datasets'\n",
    "save_path = os.path.join(save_folder, 'gtFine_trainvaltest.zip')\n",
    "extract_to_folder = os.path.join(save_folder, 'gtFine_trainvaltest')\n",
    "\n",
    "# Ensure the save folder exists\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    # Download the file\n",
    "    download_file_from_google_drive(file_id, save_path)\n",
    "\n",
    "    # Unzip the downloaded file\n",
    "    unzip_file(save_path, extract_to_folder)\n",
    "\n",
    "else:\n",
    "    print(\"File already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CityScapes Images\n",
    "\n",
    "file_id = '1sQuChAIdEcSQ78J3lCEcHgu5qvvdZicJ' # https://drive.google.com/file/d/1sQuChAIdEcSQ78J3lCEcHgu5qvvdZicJ/view?usp=sharing\n",
    "save_folder = os.getcwd()+'/datasets'\n",
    "save_path = os.path.join(save_folder, 'leftImg8bit_trainvaltest.zip')\n",
    "extract_to_folder = os.path.join(save_folder, 'leftImg8bit_trainvaltest')\n",
    "\n",
    "# Ensure the save folder exists\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    # Download the file\n",
    "    download_file_from_google_drive(file_id, save_path)\n",
    "\n",
    "    # Unzip the downloaded file\n",
    "    unzip_file(save_path, extract_to_folder)\n",
    "\n",
    "else:\n",
    "    print(\"File already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IKA Test Dataset\n",
    "\n",
    "file_id = '12vuR2iRM42L4Y34jB-Dl5IwZDRf3-qLv' #https://drive.google.com/file/d/12vuR2iRM42L4Y34jB-Dl5IwZDRf3-qLv/view?usp=drive_link\n",
    "save_folder = os.getcwd()+'/datasets'\n",
    "save_path = os.path.join(save_folder, 'ika-dataset.zip')\n",
    "extract_to_folder = os.path.join(save_folder, '')\n",
    "\n",
    "# Ensure the save folder exists\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    # Download the file\n",
    "    download_file_from_google_drive(file_id, save_path)\n",
    "\n",
    "    # Unzip the downloaded file\n",
    "    unzip_file(save_path, extract_to_folder)\n",
    "\n",
    "else:\n",
    "    print(\"File already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Abstract**\n",
    "\n",
    "**Semantic image segmentation is an important task in computer vision, particularly for applications such as autonomous driving and medical imaging. Its performance is mainly limited by the availability of labelled standardised datasets. In addition, models trained on one dataset often exhibit poor performance when applied to data from different domains due to domain shift. Domain adaptation can be used to address this issue by improving model generalization across various domains. The following report investigates the effectiveness of augmentation and hyperparameter optimization techniques in domain adaptation for semantic image segmentation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**\n",
    "\n",
    "Semantic image segmentation is simply the task of assigning a class label to every single pixel of an input image ([Fig.1](https://cdn.prod.website-files.com/614c82ed388d53640613982e/63f4aabd9537d009915e9d44_computer%20vision%20based%20self%20driving%20cars.gif)). As simple as it may seem it is crucial for understanding and interpreting visual information in various applications such as autonomous driving, medical imaging, and robotics. [[3]](https://arxiv.org/abs/1411.4038)[[4]](https://arxiv.org/abs/1706.05587) Accurate segmentation is of the utmost importance for the effectiveness and safety in these applications. For example, in autonomous driving, the ability to accurately segment different objects in the environment, such as vehicles, pedestrians, and road signs, is critical for navigation and decision-making.\n",
    "\n",
    "Recent advances in deep learning allow for a significant performance boost in many computer vision tasks, including semantic image segmentation. However, the success of deep learning methods typically depends on the availability of large amounts of annotated training data. Manual annotation of images with pixel-wise semantic labels is an extremely tedious and time consuming process. [[5]](https://arxiv.org/abs/1505.04597)[[6]](https://ar5iv.labs.arxiv.org/html/2112.03241) Initially taking an hour or more per image, recent semi-automatic tools manage to reduce the annotation time for common urban classes (people, road surface or vehicles), however they still require manual verification and validation.\n",
    "\n",
    "By leveraging augmentation and hyperparameter optimization techniques, our work provides a practical and effective approach to domain adaptation for semantic image segmentation, addressing the critical challenge of domain shift and enhancing model performance across diverse datasets. [[7]](https://arxiv.org/abs/1707.09465)\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://cdn.prod.website-files.com/614c82ed388d53640613982e/63f4aabd9537d009915e9d44_computer%20vision%20based%20self%20driving%20cars.gif\" width=\"700\">\n",
    "\n",
    "[Fig.1: Example of semantic image segmentation taken from CityScapes Dataset](https://cdn.prod.website-files.com/614c82ed388d53640613982e/63f4aabd9537d009915e9d44_computer%20vision%20based%20self%20driving%20cars.gif)\n",
    "\n",
    "Below, the report is structured into the following sections:<br>\n",
    "**Related Work**: Concepts defined and elaborated based on related literature.<br>\n",
    "**Methodology**: Introduction to the methodologies used to investigate the required aspects.<br>**Experiments**: Execution of the respective methods.<br>\n",
    "**Evaluation**: Categorizing, analyzing and comparing the obtained results.<br>\n",
    "**Conclusion**: A concise overview of the results and further research possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Related Work**\n",
    "\n",
    "This section introduces the reader to the basic terminology required for the following research. It comprises of references to related research work. The concepts of semantic image segmentation, the corresponding datasets and domain adaptation are enlightened upon.\n",
    "\n",
    "#### Semantic Image Segmentation\n",
    "\n",
    "In the most general terms, image segmentation is the process of partitioning an image into several regions. The pixels of these regions generally should share certain characteristics. in general, there are three groups of image segmentation tasks: Semantic segmentation, Instance segmentation and Panoptic segmentation. The defining feature of semantic segmentation that differentiates it from instance segmentation is that it does not distinguish between different objects that belong to the same class. [[8]](https://link.springer.com/article/10.1007/s13735-017-0141-z)[[9]](https://arxiv.org/abs/1801.00868)\n",
    "\n",
    "Recent research has focused on advancing segmentation models, usage of large-scale annotated datasets like KITTI and Cityscapes, and addressing domain shift through domain adaptation techniques. The model introduced by Long et al. [[3]](https://arxiv.org/abs/1411.4038) is the first deep network for semantic image segmentation which uses fully convolutional layers to process images of arbitrary size and to produce a segmentation map of the same. ParseNet overcomes some of the limitations of FCNs, by complementing these models with a global context. [[10]](https://arxiv.org/abs/1506.04579) Encoder-decoder based models are trained by minimizing a reconstruction loss between the ground truth and the predicted segmentation map. Subsequent architectures like U-Net (Ronneberger et al., 2015) [[5]](https://arxiv.org/abs/1505.04597) further improved segmentation performance, particularly in biomedical imaging, by introducing symmetric encoder-decoder structures with skip connections that combine high-level features with low-level details. The original U-Net has been modified into versions like 3D U-Net (Çiçek et al., 2016) [[11]](https://arxiv.org/abs/1606.06650) for volumetric data and Attention U-Net (Oktay et al., 2018) [[12]](https://arxiv.org/abs/1804.03999) that incorporates attention mechanisms to focus on relevant features. \n",
    "\n",
    "#### Datasets\n",
    "\n",
    "Benchmark datasets have significantly contributed to advancing semantic segmentation research. They are usually at the pixel-level or instance-level. Recent datasets offer diverse scene categories and pixel-level annotations, enabling more comprehensive evaluations of segmentation algorithms. [[13]](https://arxiv.org/abs/1612.03716)\n",
    "\n",
    "#### Domain Adaptation\n",
    "\n",
    "The main domain adaptation goal is ensuring that semantic image segmentation models perform well on real target data, by leveraging annotated, synthetic and non-annotated real data. A classical domain adaptation framework relies on either SYNTHIA [[14]](https://ieeexplore.ieee.org/document/7780721) or GTA [[15]](https://arxiv.org/abs/1608.02192) datasets as a source, and the real-world dataset, like Cityscapes, as a target. Early domain adaptation methods were directly inspired by adaptation methods invented for image classification. However semantic image segmentation is a more complex task, as labeling is done on the pixel level.  To address this , most domain adaptation semantic image segmentation methods take into account the spatial structure and the local image context, act at multiple levels of the segmentation pipeline and often combine multiple techniques. [[16]](https://arxiv.org/abs/1612.02649)\n",
    "\n",
    "Adversarial training, domain-specific normalization layers, and unsupervised domain adaptation methods have shown promising results in adapting segmentation models to unseen domains. [[17]](https://arxiv.org/abs/1802.10349) Techniques such as domain randomization, multi-modal fusion, and meta-learning have been explored to enhance model robustness and adaptability. [[18]](https://arxiv.org/abs/1703.06907) [[19]](https://arxiv.org/pdf/2009.12829) U-Net based models have been adapted to ensure effective transfer learning across domains. Techniques such as CycleGAN (Zhu et al., 2017) [[20]](https://arxiv.org/abs/1703.10593) for image-to-image translation have been employed to generate target-like images from source domain data, enabling better generalization. Additionally, domain adversarial training and self-ensembling approaches (French et al., 2018) [[21]](https://arxiv.org/abs/1706.05208) have been integrated with U-Net to enhance its adaptability. Domain adaptation methods continue to play a crucial role in improving model generalization and robustness across different domains, contributing to the advancement of semantic segmentation research.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" width=\"700\">\n",
    "\n",
    "[Fig.2: U-Net Architecture](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n",
    "\n",
    "As seen in [Fig.2](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png), each blue box corresponds to a multi-channel feature map. The number of channels is denoted on top of the box. The x-y-size is provided at the lower left edge of the box. White boxes represent copied feature maps. The arrows denote the different operations. [[5]](https://arxiv.org/abs/1505.04597)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Methodology**\n",
    "\n",
    "A few approaches were mentioned to consider and investigate the domain adaptation of semantic image segmentation.  In this section, the chosen datasets are processed and elaborated, some data augmentation techniques are visited and finally the structure and the tuning of the model itsef is examined.\n",
    "\n",
    "### Datasets\n",
    "\n",
    "Recent research has focused on advancing segmentation models, leveraging large-scale annotated datasets like KITTI and Cityscapes, and addressing domain shift through domain adaptation techniques. The KITTI dataset provides high-resolution images captured from vehicle-mounted sensors, along with pixel-level annotations for object detection, tracking, and segmentation tasks. [[1]](https://www.cvlibs.net/publications/Alhaija2018IJCV.pdf) Cityscapes, on the other hand, offers urban street scenes with fine-grained pixel-level annotations, making it suitable for semantic segmentation research. [[2]](https://www.cityscapes-dataset.com/wordpress/wp-content/papercite-data/pdf/cordts2016cityscapes.pdf)\n",
    "\n",
    "The KITTI semantic segmentation benchmark consists of 200 semantically annotated train as well as 200 test images, recorded in Germany. [[1]](https://www.cvlibs.net/publications/Alhaija2018IJCV.pdf) The CityScapes dataset was recorded in 50 German cities and offers high quality pixel-level annotations of 5000 frames (training and validation sets containing 3475 annotated images and test set containing 1525 images) with the following diversity:<br> \n",
    "Several months (spring, summer, fall),<br>\n",
    "Daytime,<br>\n",
    "Good/medium weather conditions, and<br>\n",
    "Manually selected frames. [[2]](https://www.cityscapes-dataset.com/wordpress/wp-content/papercite-data/pdf/cordts2016cityscapes.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import KITTI Dataset\n",
    "\n",
    "The image and label pairs are read from the downloaded and extracted dataset files. The list of image-label pairs is randomly shuffled to ensure a good mix of data. A ratio of 70:30 is used to split the training dataset for training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ratio of the dataset to be used for training.\n",
    "# 70% of the data will be used for training and the remaining 30% for validation.\n",
    "Training_Validation_split = 0.7\n",
    "\n",
    "# Define the paths to the directories containing the training images and labels.\n",
    "# These paths should be updated according to the actual locations of your dataset.\n",
    "KITTI_image_path_train = os.getcwd()+\"/datasets/KITTI_Dataset/training/image_2\"\n",
    "KITTI_label_path_train = os.getcwd()+\"/datasets/KITTI_Dataset/training/semantic_rgb\"\n",
    "\n",
    "# Initialize an empty list to hold pairs of image and label file paths.\n",
    "# Each pair will be a tuple (image_path, label_path).\n",
    "KITTI_image_label_pairs = [] #pair = [('image_path1.png', 'label_path1.png'),('image_path2.png', 'label_path2.png')]  tuple list\n",
    "\n",
    "# List all files in the image directory.\n",
    "images = os.listdir(KITTI_image_path_train)\n",
    "for image_file in images:\n",
    "    # Check if the file is a PNG image.\n",
    "    if image_file.endswith('.png'):\n",
    "        # Construct the full path to the image file.\n",
    "        image_path = os.path.join(KITTI_image_path_train, image_file)\n",
    "        # Construct the corresponding label file path.\n",
    "        label_path = os.path.join(KITTI_label_path_train, image_file)\n",
    "\n",
    "        # Check if the label file exists.  \n",
    "        if os.path.exists(label_path):\n",
    "           # If it exists, add the pair (image_path, label_path) to the list.\n",
    "            KITTI_image_label_pairs.append((image_path, label_path))\n",
    "\n",
    "# Randomly shuffle the list of image-label pairs to ensure a good mix of data.\n",
    "random.shuffle(KITTI_image_label_pairs)\n",
    "\n",
    "# Calculate the index at which to split the dataset into training and validation sets.\n",
    "split_index = int(Training_Validation_split * len(KITTI_image_label_pairs))\n",
    "\n",
    "# Split the dataset: \n",
    "# - The first part (up to split_index) is for training.\n",
    "# - The second part (from split_index to the end) is for validation.\n",
    "KITTI_training_image_label_pairs = KITTI_image_label_pairs[:split_index]\n",
    "KITTI_validation_image_label_pairs = KITTI_image_label_pairs[split_index:]\n",
    "\n",
    "# Read the first image from the training set to get its dimensions.\n",
    "# This will give us the height, width, and number of channels of the images in the dataset.\n",
    "KITTI_image_Height, KITTI_image_width, KITTI_num_channels = plot.imread(KITTI_training_image_label_pairs[0][0]).shape #Collects the shape of image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import CityScapes Dataset\n",
    "\n",
    "The image and label pairs are read from the downloaded and extracted dataset files respectively. This dataset already has seperate training, validation and testing image-label pairs. Since the images and labels are contained in different city folders, a function is used to iterate through all cities in the image and label directories and listing the corresponding files. The list of image-label pairs is randomly shuffled to ensure a good mix of data.\n",
    "\n",
    "The function in the cell below generates pairs of image and label file paths from the CityScapes dataset, iterating through all cities in the image_dir, and for each city, listing the image files. It checks for files ending with the respective suffix of the image files, and constructs the corresponding label file name by replacing the suffixes with that of the label files. If the label file exists in the label directory, it adds a tuple of the image and label file paths to the list of pairs. In the end a list of image-label pairs is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cityscapes_pairs(image_dir, label_dir):\n",
    "   \n",
    "    CityScape_image_label_pairs = [] #pair = [('image_path1.png', 'label_path1.png'),('image_path2.png', 'label_path2.png')]\n",
    "    cities = os.listdir(image_dir)\n",
    "   \n",
    "    for city in cities:\n",
    "        image_city_dir = os.path.join(image_dir, city)\n",
    "        label_city_dir = os.path.join(label_dir, city)\n",
    "        \n",
    "        images = os.listdir(image_city_dir)\n",
    "       \n",
    "        for image_file in images:\n",
    "            if image_file.endswith('_leftImg8bit.png'):\n",
    "                image_path = os.path.join(image_city_dir, image_file)\n",
    "                label_file = image_file.replace('_leftImg8bit.png', '_gtFine_color.png')\n",
    "                label_path = os.path.join(label_city_dir, label_file)\n",
    "               \n",
    "                if os.path.exists(label_path):\n",
    "                    CityScape_image_label_pairs.append((image_path, label_path))\n",
    "   \n",
    "    return CityScape_image_label_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Dataset\n",
    "# Directories\n",
    "image_dir = os.getcwd()+\"/datasets/leftImg8bit_trainvaltest/leftImg8bit/train\"\n",
    "label_dir = os.getcwd()+\"/datasets/gtFine_trainvaltest/gtFine/train\"\n",
    "\n",
    "# Load pairs\n",
    "CityScape_training_image_label_pairs = load_cityscapes_pairs(image_dir, label_dir)\n",
    "\n",
    "#Shuffle the dataset\n",
    "random.shuffle(CityScape_training_image_label_pairs)\n",
    "\n",
    "CityScape_image_Height, CityScape_image_width, CityScape_num_channels = plot.imread(CityScape_training_image_label_pairs[0][0]).shape #Collects the shape of image\n",
    "\n",
    "\n",
    "\n",
    "#Validation Dataset\n",
    "# Directories\n",
    "image_dir = os.getcwd()+\"/datasets/leftImg8bit_trainvaltest/leftImg8bit/val\"\n",
    "label_dir = os.getcwd()+\"/datasets/gtFine_trainvaltest/gtFine/val\"\n",
    "\n",
    "# Load pairs\n",
    "CityScape_validation_image_label_pairs = load_cityscapes_pairs(image_dir, label_dir)\n",
    "\n",
    "#Shuffle the dataset\n",
    "random.shuffle(CityScape_validation_image_label_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A smaller subset is created from the larger CityScapes dataset from the Cologne data (154 image-label pairs) as the training dataset and the Lindau data (59 image-label pairs) as the validation dataset. This allows for cross-validation with similar-sized KITTI dataset and speeds up the runtime for training the models so as to achieve results with more hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create CityScape subset dataset\n",
    "\n",
    "CityScape_subset_training_image_label_pairs = []\n",
    "\n",
    "for train_pair in CityScape_training_image_label_pairs:\n",
    "    if 'cologne' in train_pair[0]:\n",
    "        CityScape_subset_training_image_label_pairs.append(train_pair)\n",
    "\n",
    "\n",
    "CityScape_subset_validation_image_label_pairs = []\n",
    "\n",
    "for val_pair in CityScape_validation_image_label_pairs:\n",
    "    if 'lindau' in val_pair[0]:\n",
    "        CityScape_subset_validation_image_label_pairs.append(val_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the KITTI and CityScape image-label pairs are merged. This dataset contains the most image-label pairs, but would require a significant amount of training time compared to the previously created datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dataset\n",
    "\n",
    "merged_training_image_label_pairs = KITTI_training_image_label_pairs.copy()\n",
    "merged_training_image_label_pairs.extend(CityScape_training_image_label_pairs)\n",
    "\n",
    "#Shuffle the dataset\n",
    "random.shuffle(merged_training_image_label_pairs)\n",
    "\n",
    "\n",
    "#Validation dataset\n",
    "\n",
    "merged_validation_image_label_pairs = KITTI_validation_image_label_pairs.copy()\n",
    "merged_validation_image_label_pairs.extend(CityScape_validation_image_label_pairs)\n",
    "\n",
    "#Shuffle the dataset\n",
    "random.shuffle(merged_validation_image_label_pairs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluating the trained models the ika dataset comprising of 28 image-label pairs is used, which is comprised of images taken from the city of Aachen. This provides a base to compare the obtained results from all the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ika_dataset_image_path_train = os.getcwd()+\"/datasets/ika-dataset/input\"\n",
    "ika_dataset_label_path_train = os.getcwd()+\"/datasets/ika-dataset/label\"\n",
    "\n",
    "# Initialize an empty list to hold pairs of image and label file paths.\n",
    "# Each pair will be a tuple (image_path, label_path).\n",
    "ika_test_image_label_pairs = [] #pair = [('image_path1.png', 'label_path1.png'),('image_path2.png', 'label_path2.png')]  tuple list\n",
    "\n",
    "# List all files in the image directory.\n",
    "images = os.listdir(ika_dataset_image_path_train)\n",
    "for image_file in images:\n",
    "    # Check if the file is a PNG image.\n",
    "    if image_file.endswith('.png'):\n",
    "        # Construct the full path to the image file.\n",
    "        image_path = os.path.join(ika_dataset_image_path_train, image_file)\n",
    "        # Construct the corresponding label file path.\n",
    "        label_path = os.path.join(ika_dataset_label_path_train, image_file[0:-4] + \"_gtFine_labelColor.png\")\n",
    "\n",
    "        # Check if the label file exists.  \n",
    "        if os.path.exists(label_path):\n",
    "           # If it exists, add the pair (image_path, label_path) to the list.\n",
    "            ika_test_image_label_pairs.append((image_path, label_path))\n",
    "\n",
    "# Randomly shuffle the list of image-label pairs to ensure a good mix of data.\n",
    "random.shuffle(ika_test_image_label_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each class is associated with a certain color. The association between the color and the classes is stored in the dictionary in the given script path. It contains the mapping from the RGB color code to the class ID where each class corresponds to a semantic class such as Road, Sidewalk or Person. Since the test dataset has 12 colour association IDs, the input datasets are given the same association.\n",
    "Please find the detailed colour association with the respective class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the script containing the color association dictionary\n",
    "script_path = os.getcwd()+'/datasets/ika-dataset'\n",
    "\n",
    "# Add the script's directory to the system path\n",
    "sys.path.append(script_path)\n",
    "\n",
    "# Import the script file\n",
    "import rgb_to_class_id\n",
    "\n",
    "# Copy the dictionary contents into a new dictionary\n",
    "RGB_to_ClassID = rgb_to_class_id.rgb_to_class_id  # newDict = fileName.oldDict\n",
    "\n",
    "# To count the number of classes\n",
    "count = 0\n",
    "value_i = -1\n",
    "for key, value in RGB_to_ClassID.items():\n",
    "    if value_i == value:\n",
    "        continue\n",
    "    else:\n",
    "        count += 1\n",
    "        value_i = value\n",
    "\n",
    "num_classes = count #Stores the number of classes in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RGB Colour Code to Class ID\n",
    "\n",
    "# rgb_to_class_id = {\n",
    "\n",
    "#     (128, 64, 128):  0,   # Road\n",
    "\n",
    "#     (244, 35, 232):  1,   # Sidewalk\n",
    "\n",
    "#     ( 70,  70,  70): 2,   # Building\n",
    "#     (102, 102, 156): 2,   # Wall\n",
    "#     (150, 100, 100): 2,   # Bridge\n",
    "#     ( 50, 120,  90): 2,   # Tunnel\n",
    "#     (190, 153, 153): 2,   # Fence\n",
    "#     (180, 165, 180): 2,   # Guard rail\n",
    "\n",
    "#     (153, 153, 153): 3,   # Pole\n",
    "#     (250, 170,  30): 3,   # Traffic light\n",
    "#     (220, 220,   0): 3,   # Traffic sign\n",
    "\n",
    "#     (107, 142,  35): 4,   # Vegetation\n",
    "#     (152, 251, 152): 4,   # Terrain\n",
    "\n",
    "#     ( 70, 130, 180): 5,   # Sky\n",
    "\n",
    "#     (220,  20,  60): 6,   # Person\n",
    "\n",
    "#     (255,   0,   0): 7,   # Rider\n",
    "#     (  0,   0, 230): 7,   # Motorcycle\n",
    "#     (119,  11,  32): 7,   # Bicycle\n",
    "\n",
    "#     (  0,   0, 142): 8,   # Car\n",
    "#     (  0,   0, 110): 8,   # Trailer\n",
    "\n",
    "#     (  0,   0,  70): 9,   # Truck\n",
    "\n",
    "#     (  0,  60, 100): 10,  # Bus\n",
    "#     (  0,   0,  90): 10,  # Caravan\n",
    "\n",
    "#     (  0,   0,   0): 11,  # None\n",
    "#     ( 81,   0,  81): 11,  # Ground\n",
    "#     (111,  74,   0): 11,  # Dynamic\n",
    "#     (  0,  80, 100): 11,  # Train\n",
    "#     (250, 170, 160): 11,  # Parking\n",
    "#     (230, 150, 140): 11,  # Rail track\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many functions in the following sections are taken from the [Automated and Connected Driving Challenges](https://learning.edx.org/course/course-v1:RWTHx+ACDC+3T2023/home) course on edX. The first function converts an image with RGB class encoding into a segmentation map where each pixel is assigned a class ID based on its RGB value. For each RGB tuple and corresponding class ID , the segmentation_map tensor is updated. If a pixel is matched with the current color, the segmentation_map is updated with the class_id. Otherwise, the value remains unchanged. The final tensor is then changed from [height, width] to [height, width, 1] to make it compatible with neural network processing. The second function converts the segmentation maps to RGB images which enables the visualization of segmentation results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code taken from ACDC Course\n",
    "\n",
    "def convert_rgb_encoding_to_segmentation_map(image, RGB_to_ClassID):\n",
    "    \n",
    "    segmentation_map = tf.zeros([image.shape[0], image.shape[1]], dtype=tf.uint8)\n",
    "\n",
    "    for color, class_id in RGB_to_ClassID.items():            \n",
    "        segmentation_map = tf.where(\n",
    "                                    condition=tf.reduce_all((tf.equal(image, color)), axis = -1),\n",
    "                                    x=tf.cast(class_id, tf.uint8),\n",
    "                                    y=segmentation_map\n",
    "                                    )\n",
    "        \n",
    "    # Add dimension to change the shape from [height, width] to [height, width, 1]\n",
    "    segmentation_map = tf.expand_dims(segmentation_map, axis = -1)\n",
    "        \n",
    "    return segmentation_map\n",
    "\n",
    "\n",
    "def segmentation_map_to_rgb_encoding(segmentation_map, RGB_to_ClassID):\n",
    "    \n",
    "    rgb_encoding = npy.zeros([segmentation_map.shape[0], segmentation_map.shape[1], 3], dtype=npy.uint8)\n",
    "    \n",
    "    for color, class_id in RGB_to_ClassID.items():       \n",
    "        \n",
    "        rgb_encoding[tf.squeeze(segmentation_map)==class_id] = color  \n",
    "    \n",
    "    return rgb_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function processes the image-label pairs from the dataset. The image and label files are decoded and resized to the same size. Then the parsed label files are converted to segmentation maps using the previous function. The second function is used to normalize the range of RGB values of the image files from [0,255] to [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code taken from ACDC Course\n",
    "\n",
    "def parse_sample(image_path, label_path):\n",
    "        \n",
    "    image_rgb = tf.image.decode_png(tf.io.read_file(image_path), channels = 3)\n",
    "    label_rgb = tf.image.decode_png(tf.io.read_file(label_path), channels = 3)\n",
    "    \n",
    "    \n",
    "    # Resize all images and labels to a uniform size, because some images in the dataset have different sizes\n",
    "    image_rgb = tf.image.resize(image_rgb, [368, 1248], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    label_rgb = tf.image.resize(label_rgb, [368, 1248], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    # resize returns tf.float32 for BILINEAR, convert back to tf.uint8\n",
    "    image_rgb = tf.cast(image_rgb, tf.uint8) \n",
    "    \n",
    "    # apply convert_rgb_encoding_to_segmentation_map to the label_rgb image\n",
    "    label_segmentation_map = convert_rgb_encoding_to_segmentation_map(label_rgb, RGB_to_ClassID)\n",
    "    \n",
    "    \n",
    "    return image_rgb, label_segmentation_map\n",
    "\n",
    "\n",
    "def normalize(image, label):\n",
    "    \n",
    "    image = tf.cast(image, tf.float32) / 255.0  # image = None    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated before, labelled data for machine learning is very expensive to obtain. Augmentation techniques are used to artificially increase the size of the training dataset.\n",
    " \n",
    "The first function is used to flip the image-label pair along the 1-dimension with a defined probability. The second function is used to augment the lighting effects of the image, namely gamma, brightness and contrast. This helps simulate different illumination conditions occurring over the course of the day. Gaussian noise is added to the input images in the third function to increase the robustness of the network. The labels remain unchanged for the second and third functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from ACDC Course with modifications\n",
    "def horizontal_flip(image, label, flip_prob):\n",
    "\n",
    "    if flip_prob < tf.random.uniform(shape=[], dtype=tf.float16):\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        image = tf.image.flip_left_right(image)\n",
    "        label = tf.image.flip_left_right(label)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "\n",
    "\n",
    "def brightness_contrast_gamma(image, label, light_prob):\n",
    "    \n",
    "    if light_prob < tf.random.uniform(shape=[], dtype=tf.float16):\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    else:\n",
    "        random_gamma = tf.random.uniform(shape=[], minval=0.5, maxval=1.5, dtype=tf.float32)\n",
    "\n",
    "        image = tf.image.adjust_gamma(image, gamma=random_gamma)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "\n",
    "\n",
    "def random_noise_blur(image, label, noise_prob):\n",
    "    \n",
    "    if noise_prob < tf.random.uniform(shape=[], dtype=tf.float16):\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    else: \n",
    "\n",
    "        # Create a random standart deviation - simulates the intensity of the noise\n",
    "        random_stddev = tf.random.uniform(shape=[], minval=2, maxval=30, dtype=tf.float32)\n",
    "        \n",
    "        # Create a noise tensor with a shape like the input image. Use zero-mean and a random std\n",
    "        noise = tf.random.normal(tf.shape(image), mean=0.0, stddev=random_stddev, dtype=tf.float32)\n",
    "        \n",
    "        # Add the noise to the image. Cast the image to tf.float32 before the addition\n",
    "        image = tf.cast(image, dtype=tf.float32) + noise\n",
    "        \n",
    "        # Clip the values of the image to [0, 255] \n",
    "        image = tf.clip_by_value(image, 0.0, 255.0) \n",
    "        \n",
    "        # Cast the image back to tf.uint8\n",
    "        image = tf.cast(image, dtype=tf.uint8)  \n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function applies random zoom augmentation to the image-label pair, cropping it by a random scale and then resizing to its original dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from ACDC Course\n",
    "def random_zoom(image, label, zoom_prob):\n",
    "    \"\"\"\n",
    "    Randomly applies random zoom augmentation to the image-label pair. Randomly resizes the image \n",
    "    and then crops it back to original size.\n",
    "    \n",
    "    Arguments:\n",
    "    image -- tf.Tensor with shape [width, height, 3] representing the camera RGB image\n",
    "    label -- tf.Tensor with shape [width, height] representing the corresponding segmentation map\n",
    "    \n",
    "    Returns:\n",
    "    image -- Augmented tf.Tensor with shape [width, height, 3] representing the camera RGB image\n",
    "    label -- Augmented tf.Tensor with shape [width, height] representing the corresponding segmentation map\n",
    "    \"\"\"\n",
    "\n",
    "    if zoom_prob < tf.random.uniform(shape=[], dtype=tf.float16):\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    else:\n",
    "\n",
    "        # Store the original height, width of the input image\n",
    "        original_shape = tf.shape(image)[:2]\n",
    "        \n",
    "        # Create a random scale between 1 und 2.5\n",
    "        scale = tf.random.uniform(shape=[], minval=1, maxval=2.5, dtype=tf.float32)\n",
    "        \n",
    "        # Calculate the new dimension after scaling the the original image with scale\n",
    "        new_dim = tf.cast(tf.cast([image.shape[0], image.shape[1]], tf.float32)*scale, tf.int32)\n",
    "        \n",
    "        # Resize the image to the new dimension  \n",
    "        image = tf.image.resize(image, new_dim, method=tf.image.ResizeMethod.BILINEAR)\n",
    "        label = tf.image.resize(label, new_dim, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        \n",
    "        # Resize returns tf.float32 for BILINEAR, convert back to tf.uint8\n",
    "        image = tf.cast(image, tf.uint8)  \n",
    "        \n",
    "        # Calculate the positions boundaries of the top left corner of the new crop\n",
    "        min_top_left = tf.constant([0, 0], dtype=tf.int32)\n",
    "        max_top_left = new_dim - original_shape\n",
    "        \n",
    "        # Generate a random position of the new crop\n",
    "        x_top_left, y_top_left = min_top_left[1], min_top_left[0]\n",
    "        if min_top_left[1] < max_top_left[1]:\n",
    "            x_top_left = tf.random.uniform(shape=[], minval=min_top_left[1], maxval=max_top_left[1], dtype=tf.int32)\n",
    "        if min_top_left[0] < max_top_left[0]:\n",
    "            y_top_left = tf.random.uniform(shape=[], minval=min_top_left[0], maxval=max_top_left[0], dtype=tf.int32)\n",
    "        \n",
    "        # Crop the original image using the original shape and the new random position\n",
    "        image = tf.image.crop_to_bounding_box(\n",
    "            image=image,                      \n",
    "            offset_height=y_top_left,         \n",
    "            offset_width=x_top_left,          \n",
    "            target_height=original_shape[0],  \n",
    "            target_width=original_shape[1]    \n",
    "        )\n",
    "        # Crop the original label using the original shape and the new random position\n",
    "        label = tf.image.crop_to_bounding_box(\n",
    "            image=label,                       \n",
    "            offset_height=y_top_left,          \n",
    "            offset_width=x_top_left,           \n",
    "            target_height=original_shape[0],   \n",
    "            target_width=original_shape[1]     \n",
    "        )\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a sample of the defined augmentations with the RGB values and colour-coded class labels is shown and compared with its original image-label pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_number = tf.random.uniform(shape=[], minval=0, maxval=200, dtype=tf.int32)\n",
    "\n",
    "sample_image, sample_label = parse_sample(KITTI_image_label_pairs[sample_number][0], KITTI_image_label_pairs[sample_number][1])\n",
    "\n",
    "image_flip, label_flip = horizontal_flip(sample_image, sample_label, 1)\n",
    "image_zoom, label_zoom = random_zoom(sample_image, sample_label, 1)\n",
    "image_light, label_light = brightness_contrast_gamma(sample_image, sample_label, 1)\n",
    "image_noise, label_noise = random_noise_blur(sample_image, sample_label, 1)\n",
    "\n",
    "image_label_pairs = [\n",
    "    (sample_image, sample_label, \"Original\"),\n",
    "    (image_flip, label_flip, \"Hoizontally Flipped\"),\n",
    "    (image_zoom, label_zoom, \"Zoomed\"),\n",
    "    (image_light, label_light, \"Brightness/Contrast/Gamma Adjusted\"),\n",
    "    (image_noise, label_noise, \"Noise/Blur Added\")\n",
    "]\n",
    "\n",
    "fig, axs = plot.subplots(len(image_label_pairs), 2, figsize=(16, 16))\n",
    "\n",
    "# Loop over the image-label pairs\n",
    "for i, (image, label, title) in enumerate(image_label_pairs):\n",
    "    # Image\n",
    "    axs[i,0].imshow(image.numpy())\n",
    "    axs[i,0].set_title(f\"{title} Image\")\n",
    "    axs[i,0].axis('off')\n",
    "\n",
    "    # Label\n",
    "    axs[i,1].imshow(label.numpy())\n",
    "    axs[i,1].set_title(f\"{title} Label\")\n",
    "    axs[i,1].axis('off')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plot.tight_layout()\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The augmentation wrapper applies the augmentations in order, with horizontal flipping applied first. Each augmentation has an individual probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_wrapper(image, label):\n",
    "\n",
    "    image, label = horizontal_flip(image, label, flip_prob) \n",
    "    image, label = random_zoom(image, label, zoom_prob)\n",
    "    image, label = brightness_contrast_gamma(image, label, light_prob)\n",
    "    image, label = random_noise_blur(image, label, noise_prob)\n",
    "        \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data pipeline is built for efficient loading, preprocessing, and batching of images and their corresponding labels. First the image and label paths are converted into a dataset of tuples, which is shuffled to ensure that the samples are presented in a random order during training. The resulting dataset is then parsed with the number of parallel calls set to 'AUTOTUNE' to optimize performance. The augmentations are then applied on the dataset based on the boolean value of the corresponding variable. If the boolean is true, the augmented dataset is added to the original dataset (in this case 50% of the original dataset size). The normalization function is applied and then multiple samples of the dataset are combined into a single batch. Finally, the dataset is prefetched to improve performance by preparing the next batch of data while the current batch is being processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from ACDC Course with modifications\n",
    "\n",
    "def create_dataset(image_label_pairs, batch_size, buffer_size=200, do_augmentation=False):\n",
    "    \n",
    "    image_path_list = []\n",
    "    label_path_list = []\n",
    "\n",
    "    for iterator in image_label_pairs:\n",
    "        image_path_list.append(iterator[0])\n",
    "        label_path_list.append(iterator[1])\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((image_path_list, label_path_list))\n",
    "    \n",
    "    # Shuffle the dataset with buffer_size\n",
    "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    # Apply the parse_sample function. Use tf.data.AUTOTUNE for the number of parallel calls\n",
    "    dataset = dataset.map(parse_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Apply augmentation policy\n",
    "    if do_augmentation:\n",
    "        aug_dataset = dataset.take(tf.data.experimental.cardinality(dataset).numpy()//2)\n",
    "        aug_dataset = aug_dataset.map(augmentation_wrapper, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        dataset = dataset.concatenate(aug_dataset)\n",
    "        dataset = dataset.shuffle(buffer_size=200)\n",
    "\n",
    "    dataset = dataset.map(normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    # Apply batching to the dataset using batch_size\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    # Use prefetching\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*MR6_IaOCoxbXRPuFbIJlUg.jpeg\" width =\"700\">\n",
    "\n",
    "[Fig. 3: Encoder-Decoder Architecture](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*MR6_IaOCoxbXRPuFbIJlUg.jpeg)\n",
    "\n",
    "The above image illustrates an encoder-decoder architecture where the encoder extracts and compresses input features and subsequently the decoder reconstructs the output from these features. \n",
    "\n",
    "The encoder function builds the downsampling part of the U-Net architecture.\n",
    "First, the current tensor is initialized with the input tensor and a list is created to store the output of each layer in the encoder. Then 2-dimensional convolutional layers are successively created over the depth of the encoder. L2 regularization is also used to penalize large weights, reducing overfitting. Batch normalization is applied to the output of every convolution layer, thus stabilizing and speeding up training. After each pair of convolutional layers, the max pooling operation downsamples the feature map to half its original spatial dimensions. Dropout randomly drops a fraction of the input units at each update during training, which helps prevent overfitting.\n",
    "\n",
    "The decoder function reconstructs the high-resolution output from the compressed features generated by the encoder. It starts with the deepest layer of the encoder which contains the most compressed representation of the input features. The layers undergo successive upsampling over the depth of the network, thus increasing the spatial dimensions while reducing the number of filters. The output of the current layer in the decoder is concatenated with the corresponding layer from the encoder. This skip connection helps retain spatial information that might have been lost during downsampling in the encoder. Convolution layers are then applied to refine the features further. Finally, batch normalization and dropout are applied to normalize activations and prevent overfitting respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code taken from ACDC Course with modifications\n",
    "\n",
    "def encoder(input,\n",
    "            udepth,\n",
    "            filters1,\n",
    "            kernel_size,\n",
    "            activation,\n",
    "            batch_norm,\n",
    "            dropout,\n",
    "            l2_weight_decay):  # Add weight_decay parameter\n",
    "\n",
    "    t = input\n",
    "    encoder_layers = udepth * [None]\n",
    "\n",
    "    # layer creation with successive pooling\n",
    "    for d in range(udepth):\n",
    "        filters = (2**d) * filters1\n",
    "        t = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   padding=\"same\",\n",
    "                   activation=activation,\n",
    "                   kernel_regularizer=l2(l2_weight_decay))(t)  # Add weight decay\n",
    "        t = BatchNormalization()(t) if batch_norm else t\n",
    "        t = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   padding=\"same\",\n",
    "                   activation=activation,\n",
    "                   kernel_regularizer=l2(l2_weight_decay))(t)  # Add weight decay\n",
    "        t = encoder_layers[d] = BatchNormalization()(t) if batch_norm else t\n",
    "        if d < (udepth - 1):\n",
    "            t = MaxPooling2D(pool_size=(2, 2), padding=\"same\")(t)\n",
    "            t = Dropout(rate=dropout)(t) if dropout > 0 else t\n",
    "\n",
    "    return encoder_layers\n",
    "\n",
    "def decoder(encoder_layers,\n",
    "            udepth,\n",
    "            filters1,\n",
    "            kernel_size,\n",
    "            activation,\n",
    "            batch_norm,\n",
    "            dropout,\n",
    "            l2_weight_decay):  # Add weight_decay parameter\n",
    "\n",
    "    # start at lowest encoder layer\n",
    "    t = encoder_layers[udepth - 1]\n",
    "\n",
    "    # layer expansion symmetric to encoder\n",
    "    for d in reversed(range(udepth - 1)):\n",
    "        filters = (2**d) * filters1\n",
    "        t = Conv2DTranspose(filters=filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            strides=(2, 2),\n",
    "                            padding=\"same\",\n",
    "                            kernel_regularizer=l2(l2_weight_decay))(t)  # Add weight decay\n",
    "\n",
    "        t = Concatenate()([encoder_layers[d], t])\n",
    "        t = Dropout(rate=dropout)(t) if dropout > 0 else t\n",
    "        t = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   padding=\"same\",\n",
    "                   activation=activation,\n",
    "                   kernel_regularizer=l2(l2_weight_decay))(t)  # Add weight decay\n",
    "        t = BatchNormalization()(t) if batch_norm else t\n",
    "        t = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   padding=\"same\",\n",
    "                   activation=activation,\n",
    "                   kernel_regularizer=l2(l2_weight_decay))(t)  # Add weight decay\n",
    "        t = BatchNormalization()(t) if batch_norm else t\n",
    "\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function assembles the U-Net architecture and returns a Keras model which can be trained, saved and loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code taken from ACDC Course with modifications\n",
    "\n",
    "def getModel(input_shape,\n",
    "             num_classes,\n",
    "             udepth,\n",
    "             filters1,\n",
    "             kernel_size,\n",
    "             activation,\n",
    "             batch_norm=True,\n",
    "             dropout = 0.1,\n",
    "             l2_weight_decay = 0):  # Add l2_weight_decay parameter\n",
    "\n",
    "    \n",
    "    # create input layer\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    # construct encoder\n",
    "    encoder_layers = encoder(input=input_tensor,\n",
    "                             udepth=udepth,\n",
    "                             filters1=filters1,\n",
    "                             kernel_size=kernel_size,\n",
    "                             activation=activation,\n",
    "                             batch_norm=batch_norm,\n",
    "                             dropout=dropout,\n",
    "                             l2_weight_decay=l2_weight_decay  # Pass l2_weight_decay\n",
    "                            )\n",
    "\n",
    "    # construct decoder\n",
    "    reconstruction = decoder(encoder_layers=encoder_layers,\n",
    "                             udepth=udepth,\n",
    "                             filters1=filters1,\n",
    "                             kernel_size=kernel_size,\n",
    "                             activation=activation,\n",
    "                             batch_norm=batch_norm,\n",
    "                             dropout=dropout,\n",
    "                             l2_weight_decay=l2_weight_decay  # Pass l2_weight_decay\n",
    "                            )\n",
    "\n",
    "    # build final prediction layer\n",
    "    logits = Conv2D(filters=num_classes,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding=\"same\",\n",
    "                    activation=activation)(reconstruction)\n",
    "    \n",
    "    # apply softmax activation function to the logits \n",
    "    probabilities = Activation(\"softmax\")(logits)\n",
    "    \n",
    "    # create a Keras model\n",
    "    segmentation_model = Model(inputs=input_tensor, outputs=probabilities)\n",
    "    \n",
    "    return segmentation_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to define, compile, and train the CNN model. The image-label input is set to (368, 1248, 3), which translates to the pairs having a  size of 368x1248 with 3 color channels. The model is compiled using the Adam optimizer with a specified learning rate, with the appropriate loss function and evaluation metric for segmentation tasks. Adam combines the advantages of AdaGrad (adaptive learning rates) and RMSProp (gradient normalization). Callback functions depending on validation loss are implemented. 'EarlyStopping' stops training when the validation loss stops improving, thus preventing overfitting.'ReduceLROnPlateau' reduces the learning rate when a plateau in the validation loss is detected. The model is then trained with the input training and validation datasets. After training, the history of training metrics (Mean Intersection over Union and loss) is recorded. The sparse cross entropy loss function is used since there are multiple classes and the labels are in the form of one-hot representations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model(num_classes, udepth, filters1, kernel_size, activation, dropout, weight_decay, training_dataset, validation_dataset, batch_size, epochs = 1000, early_stopping_patience = 10, reduce_lr_patience = 5, learning_rate = 0.001):\n",
    "    # Model Definition\n",
    "    model = getModel(input_shape=(368, 1248, 3),\n",
    "                 num_classes=num_classes,\n",
    "                 udepth=udepth,\n",
    "                 filters1=filters1,\n",
    "                 kernel_size=kernel_size,\n",
    "                 activation=activation,\n",
    "                 batch_norm=True,\n",
    "                 dropout=dropout,\n",
    "                 l2_weight_decay=weight_decay)\n",
    "    # print(model.summary())\n",
    "\n",
    "    # Model Compiling\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[SparseMeanIoU(num_classes=num_classes, name=\"MIoU\")])\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=reduce_lr_patience)\n",
    "    best_metrics_callback = BestMetricsCallback()\n",
    "\n",
    "    # Model Training\n",
    "    history = model.fit(training_dataset, \n",
    "                    validation_data = validation_dataset, \n",
    "                    epochs = epochs, \n",
    "                    callbacks=[early_stopping, reduce_lr, best_metrics_callback],\n",
    "                    batch_size = batch_size,\n",
    "                    verbose = 1\n",
    "                    )\n",
    "    \n",
    "    train_miou = history.history.get('MIoU')\n",
    "    train_loss = history.history.get('loss')\n",
    "    val_miou = history.history.get('val_MIoU')\n",
    "    val_loss = history.history.get('val_loss')\n",
    "\n",
    "    best_epoch = best_metrics_callback.best_epoch\n",
    "    best_learning_rate = best_metrics_callback.best_learning_rate\n",
    "    \n",
    "    return model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate\n",
    "\n",
    "    # train_miou: List of floats\n",
    "    # train_loss: List of floats\n",
    "    # val_miou: List of floats\n",
    "    # val_loss: List of floats\n",
    "    # best_epoch: Integer\n",
    "    # best_learning_rate: Float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class called 'BestMetricsCallback' is created to return the best metric values from the model training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from ChatGPT\n",
    "\n",
    "class BestMetricsCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super(BestMetricsCallback, self).__init__()\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_epoch = -1\n",
    "        self.best_learning_rate = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_loss = logs.get('val_loss')\n",
    "        current_lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        \n",
    "        # Update best validation loss and corresponding learning rate and epoch\n",
    "        if val_loss is not None and val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.best_epoch = epoch + 1  # epoch is zero-indexed, so add 1 for human-friendly output\n",
    "            self.best_learning_rate = current_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Experiments**\n",
    "\n",
    "The functions defined in the 'Methodology' section will be used to train the CNN models. A base model is trained as a reference for each dataset as input. The following dataset combinations are used:\n",
    "1. KITTI Training and CityScape Subset Validation <br>\n",
    "2. Cityscape Subset Training and KITTI Validation <br>\n",
    "3. Merged Training and Merged Validation <br>\n",
    "\n",
    "For hyperparameter tuning, the depth of neural network (5) and number of filters (16) is kept constant. A base learning rate of 0.001 is set, which reduces over the course of training depending on the validation loss. A grid search is done on dropout rate, weight decay and batch size to find the optimum parameter values. A grid search is performed on the list of values for batch size, neural network dropout rate and weight decay. As seen below, dropout values in steps of 0.1 between 0 and 0.9, weight decay values from 0 to 1e-9 in logarithmic steps, and batch size in powers of 2 up to 32 are used. The MIoU and loss values are validated for each model with plots against each hyperparameter value. [Fig. 4](https://gombru.github.io/assets/cross_entropy_loss/intro.png) illustrates the cross entropy loss function. MIoU is the average of the IoUs (Intersections over Unions) of each individual class.  The IoU is defined as the ratio of the intersection of the predicted and true label areas to their union. [[5]](https://arxiv.org/abs/1505.04597) With the optimum parameters, augmentations are applied to figure out the optimum combination of augmentations.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://gombru.github.io/assets/cross_entropy_loss/intro.png\" width =\"700\">\n",
    "\n",
    "[Fig. 4: Cross Entropy Loss Function in CNN](https://gombru.github.io/assets/cross_entropy_loss/intro.png)\n",
    "\n",
    "\n",
    "After every grid search, a plot is generated to analyze the change in loss and MIoU metrics with increasing or changing parameter values. The optimum parameter is selected by comparing the validation loss of each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir models\n",
    "\n",
    "# Fixed Hyper Parameters (Neural Network Architecture)\n",
    "udepth = 5\n",
    "filters1 = 16\n",
    "kernel_size = (3, 3)\n",
    "activation = tf.nn.relu\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "# Hyper Parameter Space\n",
    "dropout_list = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "weight_decay_list = [0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 0.001, 0.01, 0.1]\n",
    "batch_size_list = [2, 4, 6, 8, 16, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. KITTI Training Dataset and CityScape Validation Dataset\n",
    "\n",
    "The base model with no augmentations is trained with default parameters stated in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd models && mkdir KITTI_Train_CityScape_Val\n",
    "\n",
    "training_image_label_pairs = KITTI_training_image_label_pairs\n",
    "validation_image_label_pairs = CityScape_subset_validation_image_label_pairs\n",
    "test_image_label_pairs = ika_test_image_label_pairs\n",
    "\n",
    "# Base Model Hyper Parameters\n",
    "dropout = 0.1\n",
    "weight_decay = 0\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell to test model training for the examiner\n",
    "\n",
    "training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "#Validation Dataset Creation\n",
    "validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "print(\"Validation Dataset Length:\", tf.data.experimental.cardinality(validation_dataset).numpy())\n",
    "\n",
    "#Test Dataset\n",
    "test_dataset = create_dataset(test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "#Training base model\n",
    "model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate = CNN_model(num_classes, udepth, filters1, kernel_size, activation, dropout, weight_decay, training_dataset, validation_dataset, batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KITTI-CityScape Dataset Base Model\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/KITTI_CityScape_Base_Model.weights.h5\"):\n",
    "    \n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "    print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "    #Validation Dataset Creation\n",
    "    validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "    print(\"Validation Dataset Length:\", tf.data.experimental.cardinality(validation_dataset).numpy())\n",
    "    \n",
    "    #Test Dataset\n",
    "    test_dataset = create_dataset(test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "    \n",
    "    #Training base model\n",
    "    model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate = CNN_model(num_classes, udepth, filters1, kernel_size, activation, dropout, weight_decay, training_dataset, validation_dataset, batch_size) \n",
    "    \n",
    "    test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "    \n",
    "    print(\"Best learning rate: \",best_learning_rate)\n",
    "    print(\"Training Loss: \",train_loss[best_epoch-1])\n",
    "    print(\"Training MIoU: \",train_miou[best_epoch-1])\n",
    "    print(\"Validation Loss: \",val_loss[best_epoch-1])\n",
    "    print(\"Validation MIoU: \",val_miou[best_epoch-1])\n",
    "    print(\"Test Loss: \",test_loss)\n",
    "    print(\"Test MIoU: \",test_miou)\n",
    "    print(\"Total Epochs: \",(best_epoch + 10))\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/KITTI_Train_CityScape_Val/KITTI_CityScape_Base_Model_results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best learning rate: {best_learning_rate}\\n\")\n",
    "        file.write(f\"Training Loss: {train_loss[best_epoch-1]}\\n\")\n",
    "        file.write(f\"Training MIoU: {train_miou[best_epoch-1]}\\n\")\n",
    "        file.write(f\"Validation Loss: {val_loss[best_epoch-1]}\\n\")\n",
    "        file.write(f\"Validation MIoU: {val_miou[best_epoch-1]}\\n\")\n",
    "        file.write(f\"Test Loss: {test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {test_miou}\\n\")\n",
    "        file.write(f\"Total Epochs: {best_epoch+10}\\n\")\n",
    "    # Save Model\n",
    "    model.save_weights(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/KITTI_CityScape_Base_Model.weights.h5\")\n",
    "\n",
    "else:\n",
    "    print(\"Base Model already trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Model_1 = getModel(input_shape=(368, 1248, 3),\n",
    "                num_classes = num_classes,\n",
    "                udepth = udepth,\n",
    "                filters1 = filters1,\n",
    "                kernel_size = kernel_size,\n",
    "                activation = activation,\n",
    "                batch_norm=True,\n",
    "                dropout = dropout,\n",
    "                l2_weight_decay = weight_decay)\n",
    "with open(os.getcwd()+'/models/KITTI_Train_CityScape_Val/KITTI_CityScape_Base_Model_results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best learning rate'):\n",
    "                best_learning_rate = float(line.split(':')[-1].strip())\n",
    "Base_Model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_learning_rate),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[SparseMeanIoU(num_classes=num_classes, name=\"MIoU\")])\n",
    "Base_Model_1.load_weights(os.getcwd()+'/models/KITTI_Train_CityScape_Val/KITTI_CityScape_Base_Model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Tuning Batch Size of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new folders\n",
    "\n",
    "!cd models/KITTI_Train_CityScape_Val && mkdir \"batchsize tuning\"\n",
    "!cd models/KITTI_Train_CityScape_Val/\"batchsize tuning\" && mkdir weights\n",
    "\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/batchsize tuning/results.txt\"):\n",
    "    model_list = []\n",
    "    train_miou_list = []\n",
    "    valid_miou_list = []\n",
    "    test_miou_list = []\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    test_loss_list = []\n",
    "    learning_rate_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for batch_size in batch_size_list:\n",
    "\n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "        #Validation Dataset Creation\n",
    "        validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "        #Test Dataset\n",
    "        test_dataset = create_dataset(test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "        \n",
    "        print(\"Model with batch size = \", batch_size)\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size)\n",
    "\n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "\n",
    "        model_list.append(model)\n",
    "\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        # Save Model Weights\n",
    "        file_path = 'models/KITTI_Train_CityScape_Val/batchsize tuning/weights/'+'batchsize_'+str(batch_size_list[index])+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Hyper Parameter Tuning already performed. Skipping execution of cell\")\n",
    "    with open(os.getcwd()+'/models/KITTI_Train_CityScape_Val/batchsize tuning/results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Batch Size'):\n",
    "                best_batch_size = int(line.split(':')[-1].strip())\n",
    "\n",
    "    print(\"Best Batch Size: \",best_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function defines the graph plots for loss and MIoU against the respective parameter values in the form of line graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions for Hyperparameter tuning\n",
    "def plot_loss_data(x_lists):\n",
    "    \n",
    "    plot.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot Training Loss\n",
    "    plot.plot(x_lists, train_loss_list, marker='o', linestyle='--', color='black', label = 'Training Loss')\n",
    "    \n",
    "    # Plot Validation Loss\n",
    "    plot.plot(x_lists, valid_loss_list, marker='o', linestyle='--', color='blue', label = 'Validation Loss')\n",
    "\n",
    "    # Plot Validation Loss\n",
    "    plot.plot(x_lists, test_loss_list, marker='o', linestyle='--', color='red', label = 'Test Loss')\n",
    "\n",
    "def plot_miou_data(x_lists):\n",
    "    \n",
    "    plot.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot Training Loss\n",
    "    plot.plot(x_lists, train_miou_list, marker='o', linestyle='--', color='black', label = 'Training MIoU')\n",
    "    \n",
    "    # Plot Validation Loss\n",
    "    plot.plot(x_lists, valid_miou_list, marker='o', linestyle='--', color='blue', label = 'Validation MIoU')\n",
    "\n",
    "    # Plot Test Loss\n",
    "    plot.plot(x_lists, test_miou_list, marker='o', linestyle='--', color='red', label = 'Test MIoU')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/batchsize tuning/batch_size_vs_Loss.jpg\"):\n",
    "    plot_loss_data(batch_size_list)\n",
    "    plot.xlabel('Batch Size')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Batch Size vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/batchsize tuning/batch_size_vs_Loss.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+'/models/KITTI_Train_CityScape_Val/batchsize tuning/batch_size_vs_Loss.jpg')\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/batchsize tuning/batch_size_vs_MIoU.jpg\"):\n",
    "    plot_miou_data(batch_size_list)\n",
    "    plot.xlabel('Batch Size')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Batch Size vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/batchsize tuning/batch_size_vs_MIoU.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/batchsize tuning/batch_size_vs_MIoU.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/batchsize tuning/results.txt\"):\n",
    "    best_valid_loss = 100\n",
    "    index = 0\n",
    "\n",
    "    while index < len(model_list):\n",
    "        if valid_loss_list[index] < best_valid_loss:\n",
    "            index_of_best_model = index\n",
    "            best_valid_loss = valid_loss_list[index]\n",
    "        index += 1\n",
    "\n",
    "    best_model = model_list[index_of_best_model]\n",
    "    best_batch_size = batch_size_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    Train_Loss = train_loss_list[index_of_best_model]\n",
    "    Train_MIoU = train_miou_list[index_of_best_model]\n",
    "    Val_Loss = valid_loss_list[index_of_best_model]\n",
    "    Val_MIoU = valid_miou_list[index_of_best_model]\n",
    "    Test_loss = test_loss_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    total_epochs = epoch_list[index_of_best_model]\n",
    "\n",
    "    print(\"Best Batch Size: \",best_batch_size)\n",
    "    print(\"Training Loss: \",Train_Loss)\n",
    "    print(\"Training MIoU: \",Train_MIoU)\n",
    "    print(\"Validation Loss: \",Val_Loss)\n",
    "    print(\"Validation MIoU: \",Val_MIoU)\n",
    "    print(\"Test Loss: \",Test_loss)\n",
    "    print(\"Test MIoU: \",Test_MIoU)\n",
    "    print(\"Total Epochs: \",total_epochs)\n",
    "\n",
    "    #  Save Best Model Weights\n",
    "    file_path = os.getcwd()+'/models/KITTI_Train_CityScape_Val/batchsize tuning/best_batchsize_model_weight.weights.h5'\n",
    "    model_list[index_of_best_model].save_weights(file_path)\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/KITTI_Train_CityScape_Val/batchsize tuning/results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Batch Size: {best_batch_size}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        file.write(f\"Total Epochs: {total_epochs}\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"Results already stored in file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Tuning of Neural Network Dropout Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new folders\n",
    "\n",
    "!cd models/KITTI_Train_CityScape_Val && mkdir \"dropout tuning\"\n",
    "!cd models/KITTI_Train_CityScape_Val/\"dropout tuning\" && mkdir weights\n",
    "\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/dropout tuning/results.txt\"):\n",
    "    model_list = []\n",
    "    train_miou_list = []\n",
    "    valid_miou_list = []\n",
    "    test_miou_list = []\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    test_loss_list = []\n",
    "    learning_rate_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    #Validation Dataset Creation\n",
    "    validation_dataset = create_dataset(validation_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    #Test Dataset\n",
    "    test_dataset = create_dataset(test_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    for dropout in dropout_list:\n",
    "\n",
    "        print(\"Model with dropout = \", dropout)\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    best_batch_size)\n",
    "\n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "\n",
    "        model_list.append(model)\n",
    "\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        # Save Model Weights\n",
    "        file_path = 'models/KITTI_Train_CityScape_Val/dropout tuning/weights/'+'dropout_'+str(dropout_list[index])+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Hyper Parameter Tuning already performed. Skipping execution of cell\")\n",
    "    with open(os.getcwd()+'/models/KITTI_Train_CityScape_Val/dropout tuning/results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Dropout'):\n",
    "                best_dropout = float(line.split(':')[-1].strip())\n",
    "\n",
    "    print(\"Best Dropout: \",best_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/dropout tuning/dropout_vs_Loss.jpg\"):\n",
    "    plot_loss_data(dropout_list)\n",
    "    plot.xlabel('Dropout')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Dropout vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/dropout tuning/dropout_vs_Loss.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/dropout tuning/dropout_vs_Loss.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/dropout tuning/dropout_vs_MIoU.jpg\"):\n",
    "    plot_miou_data(dropout_list)\n",
    "    plot.xlabel('Dropout')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Dropout vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/dropout tuning/dropout_vs_MIoU.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/dropout tuning/dropout_vs_MIoU.jpg\")\n",
    "    \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/dropout tuning/results.txt\"):\n",
    "    best_valid_loss = 100\n",
    "    index = 0\n",
    "\n",
    "    while index < len(model_list):\n",
    "        if valid_loss_list[index] < best_valid_loss:\n",
    "            index_of_best_model = index\n",
    "            best_valid_loss = valid_loss_list[index]\n",
    "        index += 1\n",
    "\n",
    "    best_model = model_list[index_of_best_model]\n",
    "    best_dropout = dropout_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    Train_Loss = train_loss_list[index_of_best_model]\n",
    "    Train_MIoU = train_miou_list[index_of_best_model]\n",
    "    Val_Loss = valid_loss_list[index_of_best_model]\n",
    "    Val_MIoU = valid_miou_list[index_of_best_model]\n",
    "    Test_loss = test_loss_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    total_epochs = epoch_list[index_of_best_model]\n",
    "\n",
    "    print(\"Best Dropout: \",best_dropout)\n",
    "    print(\"Training Loss: \",Train_Loss)\n",
    "    print(\"Training MIoU: \",Train_MIoU)\n",
    "    print(\"Validation Loss: \",Val_Loss)\n",
    "    print(\"Validation MIoU: \",Val_MIoU)\n",
    "    print(\"Test Loss: \",Test_loss)\n",
    "    print(\"Test MIoU: \",Test_MIoU)\n",
    "    print(\"Total Epochs: \",total_epochs)\n",
    "\n",
    "    #  Save Best Model Weights\n",
    "    file_path = os.getcwd()+'/models/KITTI_Train_CityScape_Val/dropout tuning/best_dropout_model_weight.weights.h5'\n",
    "    model_list[index_of_best_model].save_weights(file_path)\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/KITTI_Train_CityScape_Val/dropout tuning/results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Dropout: {best_dropout}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        file.write(f\"Total Epochs: {total_epochs}\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"Results already stored in file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Tuning Neural Network Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new folders\n",
    "\n",
    "!cd models/KITTI_Train_CityScape_Val && mkdir \"weight_decay tuning\"\n",
    "!cd models/KITTI_Train_CityScape_Val/\"weight_decay tuning\" && mkdir weights\n",
    "\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/weight_decay tuning/results.txt\"):\n",
    "    model_list = []\n",
    "    train_miou_list = []\n",
    "    valid_miou_list = []\n",
    "    test_miou_list = []\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    test_loss_list = []\n",
    "    learning_rate_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    #Validation Dataset Creation\n",
    "    validation_dataset = create_dataset(validation_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    #Test Dataset\n",
    "    test_dataset = create_dataset(test_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "    \n",
    "    for weight_decay in weight_decay_list:\n",
    "\n",
    "        print(\"Model with weight_decay = \", weight_decay)\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, best_dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    best_batch_size)\n",
    "\n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "\n",
    "        model_list.append(model)\n",
    "\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        # Save Model Weights\n",
    "        file_path = 'models/KITTI_Train_CityScape_Val/weight_decay tuning/weights/'+'weight_decay_'+str(weight_decay_list[index])+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Hyper Parameter Tuning already performed. Skipping execution of cell\")\n",
    "    with open(os.getcwd()+'/models/KITTI_Train_CityScape_Val/weight_decay tuning/results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Weight Decay'):\n",
    "                best_weight_decay = float(line.split(':')[-1].strip())\n",
    "\n",
    "    print(\"Best Weight Decay: \",best_weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/weight_decay tuning/weight_decay_vs_Loss.jpg\"):\n",
    "    plot_loss_data(weight_decay_list)\n",
    "    plot.xscale('log')\n",
    "    plot.xlabel('Weight Decay')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Weight Decay vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/weight_decay tuning/weight_decay_vs_Loss.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/weight_decay tuning/weight_decay_vs_Loss.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/weight_decay tuning/weight_decay_vs_MIoU.jpg\"):\n",
    "    plot_miou_data(weight_decay_list)\n",
    "    plot.xscale('log')\n",
    "    plot.xlabel('Weight Decay')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Weight Decay vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/weight_decay tuning/weight_decay_vs_MIoU.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/weight_decay tuning/weight_decay_vs_MIoU.jpg\")\n",
    "                       \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/weight_decay tuning/results.txt\"):\n",
    "    best_test_loss = 100\n",
    "    index = 0\n",
    "\n",
    "    while index < len(model_list):\n",
    "        if valid_loss_list[index] < best_valid_loss:\n",
    "            index_of_best_model = index\n",
    "            best_valid_loss = valid_loss_list[index]\n",
    "        index += 1\n",
    "\n",
    "    best_model = model_list[index_of_best_model]\n",
    "    best_weight_decay = weight_decay_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    Train_Loss = train_loss_list[index_of_best_model]\n",
    "    Train_MIoU = train_miou_list[index_of_best_model]\n",
    "    Val_Loss = valid_loss_list[index_of_best_model]\n",
    "    Val_MIoU = valid_miou_list[index_of_best_model]\n",
    "    Test_loss = test_loss_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    total_epochs = epoch_list[index_of_best_model]\n",
    "\n",
    "    print(\"Best Weight Decay: \",best_weight_decay)\n",
    "    print(\"Training Loss: \",Train_Loss)\n",
    "    print(\"Training MIoU: \",Train_MIoU)\n",
    "    print(\"Validation Loss: \",Val_Loss)\n",
    "    print(\"Validation MIoU: \",Val_MIoU)\n",
    "    print(\"Test Loss: \",Test_loss)\n",
    "    print(\"Test MIoU: \",Test_MIoU)\n",
    "    print(\"Total Epochs: \",total_epochs)\n",
    "\n",
    "    #  Save Best Model Weights\n",
    "    file_path = os.getcwd()+'/models/KITTI_Train_CityScape_Val/weight_decay tuning/best_weight_decay_model_weight.weights.h5'\n",
    "    model_list[index_of_best_model].save_weights(file_path)\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/KITTI_Train_CityScape_Val/weight_decay tuning/results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Weight Decay: {best_weight_decay}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        file.write(f\"Total Epochs: {total_epochs}\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"Results already stored in file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell gives the best hyperparameters for the model with KITTI training and CityScape subset validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Batch Size {best_batch_size}\\nBest Dropout Rate {best_dropout}\\nBest Weight Decay {best_weight_decay}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Augmentations\n",
    "\n",
    "The augmentations are individually applied on a random half of the dataset, which is then appended to the original dataset. From the obtained results, further combinations are experimented to find the optimum combination of augmentations. The validation loss and MIoU are analyzed against each augmentation, and the best augmentation(s) are combined with the other augmentations till the optimum combination is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd models && mkdir KITTI_Train_CityScape_Val\n",
    "!cd models/KITTI_Train_CityScape_Val && mkdir augmentations\n",
    "!cd models/KITTI_Train_CityScape_Val/augmentations && mkdir weights\n",
    "\n",
    "training_image_label_pairs = KITTI_training_image_label_pairs\n",
    "validation_image_label_pairs = CityScape_subset_validation_image_label_pairs\n",
    "test_image_label_pairs = ika_test_image_label_pairs\n",
    "\n",
    "# Tuned Hyper Parameters\n",
    "udepth = 5\n",
    "filters1 = 16\n",
    "dropout = 0.5\n",
    "weight_decay = 0.0000001\n",
    "batch_size = 4\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "activation = tf.nn.relu\n",
    "\n",
    "#Validation Dataset Creation\n",
    "validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "print(\"Validation Dataset Length:\", tf.data.experimental.cardinality(validation_dataset).numpy())\n",
    "    \n",
    "\n",
    "#ika Test Dataset\n",
    "test_dataset = create_dataset(ika_test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "print(\"Test Dataset Length:\", tf.data.experimental.cardinality(test_dataset).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/Loss_single.jpg\"):\n",
    "            \n",
    "    flip_prob = zoom_prob = light_prob = noise_prob = 0\n",
    "    prob_list = [0,0,0,0]\n",
    "    prob_name = [\" Flip \", \" Zoom \", \" Lighting \", \" Noise \"]\n",
    "            \n",
    "\n",
    "    model_list = []\n",
    "    aug_names_list = []\n",
    "    train_miou_list = []\n",
    "    valid_miou_list = []\n",
    "    test_miou_list = []\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    test_loss_list = []\n",
    "    learning_rate_list = []\n",
    "    model_processing_time = []\n",
    "    epoch_list = []\n",
    "\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for prob in range(len(prob_list)):\n",
    "    \n",
    "        prob_list = [0] * len(prob_list)\n",
    "        \n",
    "        prob_list[prob] = 1\n",
    "\n",
    "        flip_prob = prob_list[0]\n",
    "        zoom_prob = prob_list[1]\n",
    "        light_prob = prob_list[2]\n",
    "        noise_prob = prob_list[3]\n",
    "        \n",
    "        aug_list = [flip_prob, zoom_prob, light_prob, noise_prob]\n",
    "        file_name = ''\n",
    "        \n",
    "        for augment in range(len(aug_list)):\n",
    "            \n",
    "            if aug_list[augment] == 1:\n",
    "                \n",
    "                file_name = file_name + str(prob_name[augment])\n",
    "            \n",
    "        print(\"Model augmented with:\", file_name)\n",
    "    \n",
    "    \n",
    "        print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "        print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size)\n",
    "        \n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "        model_list.append(model)\n",
    "        aug_names_list.append(file_name)\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        file_path = os.getcwd()+'/models/KITTI_Train_CityScape_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Augmentations already performed. Skipping execution of cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions define graph plots for loss and MIoU against the respective augmentation technique/s in the form of bar graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function for Augmentations\n",
    "def plot_loss_aug(x_lists):\n",
    "\n",
    "    # Positions of the bars on the x-axis\n",
    "    ind = npy.arange(len(x_lists))\n",
    "\n",
    "    # Width of a bar\n",
    "    width = 0.1\n",
    "\n",
    "    # Create a bar chart\n",
    "    plot.figure(figsize=(20, 6))\n",
    "    \n",
    "    plot.xticks(ind, x_lists)\n",
    "\n",
    "    # Plot Training Loss\n",
    "    plot.bar(ind - width, train_loss_list, width, color='black', label='Training Loss')\n",
    "\n",
    "    # Plot Validation Loss\n",
    "    plot.bar(ind, valid_loss_list, width, color='blue', label='Validation Loss')\n",
    "\n",
    "    # Plot Test Loss\n",
    "    plot.bar(ind + width, test_loss_list, width, color='red', label='Test Loss')\n",
    "    \n",
    "   \n",
    "def plot_miou_aug(x_lists):\n",
    "\n",
    "    # Positions of the bars on the x-axis\n",
    "    ind = npy.arange(len(x_lists))\n",
    "\n",
    "    # Width of a bar\n",
    "    width = 0.1\n",
    "\n",
    "    # Create a bar chart\n",
    "    plot.figure(figsize=(20, 6))\n",
    "    \n",
    "    plot.xticks(ind, x_lists)\n",
    "\n",
    "    # Plot Training Loss\n",
    "    plot.bar(ind - width, train_miou_list, width, color='black', label='Training MIoU')\n",
    "\n",
    "    # Plot Validation Loss\n",
    "    plot.bar(ind, valid_miou_list, width, color='blue', label='Validation MIoU')\n",
    "\n",
    "    # Plot Test Loss\n",
    "    plot.bar(ind + width, test_miou_list, width, color='red', label='Test MIoU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/Loss_single.jpg\"):\n",
    "    plot_loss_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Augmentations vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/Loss_single.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/Loss_single.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/MIoU_single.jpg\"):\n",
    "    plot_miou_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Augmentations vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/MIoU_single.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/MIoU_single.jpg\")\n",
    "                       \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/Loss_double.jpg\"):\n",
    "    \n",
    "    \n",
    "    #In combination with Flip\n",
    "    flip_prob = 1\n",
    "    zoom_prob = light_prob = noise_prob = 0\n",
    "    prob_list = [0,0,0] \n",
    "    prob_name = [\" Flip \", \" Zoom \", \" Lighting \", \" Noise \"]\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for prob in range(len(prob_list)):\n",
    "    \n",
    "        prob_list = [0] * len(prob_list)\n",
    "        \n",
    "        prob_list[prob] = 1\n",
    "\n",
    "        zoom_prob = prob_list[0]\n",
    "        light_prob = prob_list[1]\n",
    "        noise_prob = prob_list[2]\n",
    "        \n",
    "        aug_list = [flip_prob, zoom_prob, light_prob, noise_prob]\n",
    "        file_name = ''\n",
    "        \n",
    "        for augment in range(len(aug_list)):\n",
    "            \n",
    "            if aug_list[augment] == 1:\n",
    "                \n",
    "                file_name = file_name + str(prob_name[augment])\n",
    "            \n",
    "        print(\"Model augmented with:\", file_name)\n",
    "    \n",
    "    \n",
    "        print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "        print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size)\n",
    "        \n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "        model_list.append(model)\n",
    "        aug_names_list.append(file_name)\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        file_path = os.getcwd()+'/models/KITTI_Train_CityScape_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #In combination with noise\n",
    "    noise_prob = 1\n",
    "    flip_prob = light_prob = zoom_prob = 0\n",
    "    prob_list = [0,0] \n",
    "    prob_name = [\" Flip \", \" Zoom \", \" Lighting \", \" Noise \"]\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for prob in range(len(prob_list)):\n",
    "    \n",
    "        prob_list = [0] * len(prob_list)\n",
    "        \n",
    "        prob_list[prob] = 1\n",
    "\n",
    "        zoom_prob = prob_list[0]\n",
    "        light_prob = prob_list[1]\n",
    "        \n",
    "        aug_list = [flip_prob, zoom_prob, light_prob, noise_prob]\n",
    "        file_name = ''\n",
    "        \n",
    "        for augment in range(len(aug_list)):\n",
    "            \n",
    "            if aug_list[augment] == 1:\n",
    "                \n",
    "                file_name = file_name + str(prob_name[augment])\n",
    "            \n",
    "        print(\"Model augmented with:\", file_name)\n",
    "    \n",
    "    \n",
    "        print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "        print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size)\n",
    "        \n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "        model_list.append(model)\n",
    "        aug_names_list.append(file_name)\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        file_path = os.getcwd()+'/models/KITTI_Train_CityScape_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Augmentations already performed. Skipping execution of cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/Loss_double.jpg\"):\n",
    "    plot_loss_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Augmentations vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/Loss_double.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/Loss_double.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/MIoU_double.jpg\"):\n",
    "    plot_miou_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Augmentations vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/MIoU_double.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/MIoU_double.jpg\")\n",
    "                       \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/Loss_final.jpg\"):\n",
    "    \n",
    "    \n",
    "    flip_prob = noise_prob = 1\n",
    "    zoom_prob = light_prob = 0\n",
    "    prob_list = [0,0] \n",
    "    prob_name = [\" Flip \", \" Zoom \", \" Lighting \", \" Noise \"]\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for prob in range(len(prob_list)):\n",
    "    \n",
    "        prob_list = [0] * len(prob_list)\n",
    "        \n",
    "        prob_list[prob] = 1\n",
    "\n",
    "        zoom_prob = prob_list[0]\n",
    "        light_prob = prob_list[1]\n",
    "        \n",
    "        aug_list = [flip_prob, zoom_prob, light_prob, noise_prob]\n",
    "        file_name = ''\n",
    "        \n",
    "        for augment in range(len(aug_list)):\n",
    "            \n",
    "            if aug_list[augment] == 1:\n",
    "                \n",
    "                file_name = file_name + str(prob_name[augment])\n",
    "            \n",
    "        print(\"Model augmented with:\", file_name)\n",
    "    \n",
    "    \n",
    "        print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "        print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size)\n",
    "        \n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "        model_list.append(model)\n",
    "        aug_names_list.append(file_name)\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        file_path = os.getcwd()+'/models/KITTI_Train_CityScape_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #All augmentations\n",
    "    noise_prob = flip_prob = light_prob = zoom_prob = 1\n",
    "    file_name = 'All augments'\n",
    "\n",
    "    print(\"Model augmented with:\", file_name)\n",
    "    print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "    \n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "    print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "    model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                activation, dropout, weight_decay, \n",
    "                                                                                                training_dataset, validation_dataset, \n",
    "                                                                                                batch_size)\n",
    "\n",
    "    test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "    model_list.append(model)\n",
    "    aug_names_list.append(file_name)\n",
    "    train_miou_list.append(train_miou[best_epoch-1])\n",
    "    train_loss_list.append(train_loss[best_epoch-1])\n",
    "    valid_miou_list.append(val_miou[best_epoch-1])\n",
    "    valid_loss_list.append(val_loss[best_epoch-1])\n",
    "    test_miou_list.append(test_miou)\n",
    "    test_loss_list.append(test_loss)\n",
    "    learning_rate_list.append(best_learning_rate)\n",
    "    epoch_list.append((best_epoch + 10))\n",
    "\n",
    "    file_path = os.getcwd()+'/models/KITTI_Train_CityScape_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "    model_list[index].save_weights(file_path)\n",
    "    index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Augmentations already performed. Skipping execution of cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/Loss_final.jpg\"):\n",
    "    plot_loss_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Augmentations vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/Loss_final.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/Loss_final.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/MIoU_final.jpg\"):\n",
    "    plot_miou_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Augmentations vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/MIoU_final.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/graphs/MIoU_final.jpg\")\n",
    "                       \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/augmentations/results.txt\"):\n",
    "    best_test_loss = 1000\n",
    "    index = 0\n",
    "\n",
    "    while index < len(model_list):\n",
    "        if test_loss_list[index] < best_test_loss:\n",
    "            index_of_best_model = index\n",
    "            best_test_loss = test_loss_list[index]\n",
    "        index += 1\n",
    "\n",
    "    best_model = model_list[index_of_best_model]\n",
    "    best_augmentation = aug_names_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    Train_Loss = train_loss_list[index_of_best_model]\n",
    "    Train_MIoU = train_miou_list[index_of_best_model]\n",
    "    Val_Loss = valid_loss_list[index_of_best_model]\n",
    "    Val_MIoU = valid_miou_list[index_of_best_model]\n",
    "    Test_loss = test_loss_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "\n",
    "    print(\"Best Augmentation: \",best_augmentation)\n",
    "    print(\"Training Loss: \",Train_Loss)\n",
    "    print(\"Training MIoU: \",Train_MIoU)\n",
    "    print(\"Validation Loss: \",Val_Loss)\n",
    "    print(\"Validation MIoU: \",Val_MIoU)\n",
    "    print(\"Test Loss: \",Test_loss)\n",
    "    print(\"Test MIoU: \",Test_MIoU)\n",
    "\n",
    "    #  Save Best Model Weights\n",
    "    file_path = os.getcwd()+'/models/KITTI_Train_CityScape_Val/augmentations/best_augmentation_model_weight.weights.h5'\n",
    "    model_list[index_of_best_model].save_weights(file_path)\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/KITTI_Train_CityScape_Val/augmentations/results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Augmentation: {best_augmentation}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"Results already stored in file\")\n",
    "    with open(os.getcwd()+'/models/KITTI_Train_CityScape_Val/augmentations/results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Augmentation'):\n",
    "                best_aug = str(line.split(':')[-1].strip())\n",
    "\n",
    "    print(\"Best Augmentation: \",best_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CityScape Training Dataset and KITTI Validation Dataset\n",
    "\n",
    "Now the second set of datasets are used: the CityScape subset training dataset and KITTI validation datasets. The same sets of experiments implemented previously are conducted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd models && mkdir CityScape_Train_KITTI_Val\n",
    "\n",
    "training_image_label_pairs = CityScape_subset_training_image_label_pairs\n",
    "validation_image_label_pairs = KITTI_validation_image_label_pairs\n",
    "test_image_label_pairs = ika_test_image_label_pairs\n",
    "\n",
    "# Base Model Hyper Parameters\n",
    "dropout = 0.1\n",
    "weight_decay = 0\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell to test model training for the examiner\n",
    "\n",
    "training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "#Validation Dataset Creation\n",
    "validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "print(\"Validation Dataset Length:\", tf.data.experimental.cardinality(validation_dataset).numpy())\n",
    "\n",
    "#Test Dataset\n",
    "test_dataset = create_dataset(test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "#Training base model\n",
    "model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate = CNN_model(num_classes, udepth, filters1, kernel_size, activation, dropout, weight_decay, training_dataset, validation_dataset, batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CityScape-KITTI Dataset Base Model\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/CityScape_KITTI_Base_Model.weights.h5\"):\n",
    "    \n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "    print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "    #Validation Dataset Creation\n",
    "    validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "    print(\"Validation Dataset Length:\", tf.data.experimental.cardinality(validation_dataset).numpy())\n",
    "    \n",
    "    #Test Dataset\n",
    "    test_dataset = create_dataset(test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "    \n",
    "\n",
    "    #Training base model\n",
    "    model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate = CNN_model(num_classes, udepth, filters1, kernel_size, activation, dropout, weight_decay, training_dataset, validation_dataset, batch_size) \n",
    "    \n",
    "    test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "    \n",
    "    print(\"Best learning rate: \",best_learning_rate)\n",
    "    print(\"Training Loss: \",train_loss[best_epoch-1])\n",
    "    print(\"Training MIoU: \",train_miou[best_epoch-1])\n",
    "    print(\"Validation Loss: \",val_loss[best_epoch-1])\n",
    "    print(\"Validation MIoU: \",val_miou[best_epoch-1])\n",
    "    print(\"Test Loss: \",test_loss)\n",
    "    print(\"Test MIoU: \",test_miou)\n",
    "    print(\"Total Epochs: \",(best_epoch + 10))\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/CityScape_Train_KITTI_Val/CityScape_KITTI_Base_Model_results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best learning rate: {best_learning_rate}\\n\")\n",
    "        file.write(f\"Training Loss: {train_loss[best_epoch-1]}\\n\")\n",
    "        file.write(f\"Training MIoU: {train_miou[best_epoch-1]}\\n\")\n",
    "        file.write(f\"Validation Loss: {val_loss[best_epoch-1]}\\n\")\n",
    "        file.write(f\"Validation MIoU: {val_miou[best_epoch-1]}\\n\")\n",
    "        file.write(f\"Test Loss: {test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {test_miou}\\n\")\n",
    "        file.write(f\"Total Epochs: {best_epoch+10}\\n\")\n",
    "    # Save Model\n",
    "    model.save_weights(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/CityScape_KITTI_Base_Model.weights.h5\")\n",
    "\n",
    "else:\n",
    "    \n",
    "    print(\"Base Model already trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Model_2 = getModel(input_shape=(368, 1248, 3),\n",
    "                num_classes = num_classes,\n",
    "                udepth = udepth,\n",
    "                filters1 = filters1,\n",
    "                kernel_size = kernel_size,\n",
    "                activation = activation,\n",
    "                batch_norm=True,\n",
    "                dropout = dropout,\n",
    "                l2_weight_decay = weight_decay)\n",
    "with open(os.getcwd()+'/models/CityScape_Train_KITTI_Val/CityScape_KITTI_Base_Model_results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best learning rate'):\n",
    "                best_learning_rate = float(line.split(':')[-1].strip())\n",
    "Base_Model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_learning_rate),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[SparseMeanIoU(num_classes=num_classes, name=\"MIoU\")])\n",
    "Base_Model_2.load_weights(os.getcwd()+'/models/CityScape_Train_KITTI_Val/CityScape_KITTI_Base_Model.weights.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Tuning Batch Size of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new folders\n",
    "\n",
    "!cd models/CityScape_Train_KITTI_Val && mkdir \"batchsize tuning\"\n",
    "!cd models/CityScape_Train_KITTI_Val/\"batchsize tuning\" && mkdir weights\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/batchsize tuning/results.txt\"):\n",
    "    model_list = []\n",
    "    train_miou_list = []\n",
    "    valid_miou_list = []\n",
    "    test_miou_list = []\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    test_loss_list = []\n",
    "    learning_rate_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for batch_size in batch_size_list:\n",
    "\n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "        #Validation Dataset Creation\n",
    "        validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "        #Test Dataset\n",
    "        test_dataset = create_dataset(test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "        \n",
    "        print(\"Model with batch size = \", batch_size)\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size)\n",
    "\n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "\n",
    "        model_list.append(model)\n",
    "\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        # Save Model Weights\n",
    "        file_path = 'models/CityScape_Train_KITTI_Val/batchsize tuning/weights/'+'batchsize_'+str(batch_size_list[index])+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Hyper Parameter Tuning already performed. Skipping execution of cell\")\n",
    "    with open(os.getcwd()+'/models/CityScape_Train_KITTI_Val/batchsize tuning/results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Batch Size'):\n",
    "                best_batch_size = int(line.split(':')[-1].strip())\n",
    "\n",
    "    print(\"Best Batch Size: \",best_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/batchsize tuning/batch_size_vs_Loss.jpg\"):\n",
    "    plot_loss_data(batch_size_list)\n",
    "    plot.xlabel('Batch Size')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Batch Size vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/batchsize tuning/batch_size_vs_Loss.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+'/models/CityScape_Train_KITTI_Val/batchsize tuning/batch_size_vs_Loss.jpg')\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/batchsize tuning/batch_size_vs_MIoU.jpg\"):\n",
    "    plot_miou_data(batch_size_list)\n",
    "    plot.xlabel('Batch Size')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Batch Size vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/batchsize tuning/batch_size_vs_MIoU.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/batchsize tuning/batch_size_vs_MIoU.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/batchsize tuning/results.txt\"):\n",
    "    best_valid_loss = 100\n",
    "    index = 0\n",
    "\n",
    "    while index < len(model_list):\n",
    "        if valid_loss_list[index] < best_valid_loss:\n",
    "            index_of_best_model = index\n",
    "            best_valid_loss = valid_loss_list[index]\n",
    "        index += 1\n",
    "\n",
    "    best_model = model_list[index_of_best_model]\n",
    "    best_batch_size = batch_size_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    Train_Loss = train_loss_list[index_of_best_model]\n",
    "    Train_MIoU = train_miou_list[index_of_best_model]\n",
    "    Val_Loss = valid_loss_list[index_of_best_model]\n",
    "    Val_MIoU = valid_miou_list[index_of_best_model]\n",
    "    Test_loss = test_loss_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    total_epochs = epoch_list[index_of_best_model]\n",
    "\n",
    "    print(\"Best Batch Size: \",best_batch_size)\n",
    "    print(\"Training Loss: \",Train_Loss)\n",
    "    print(\"Training MIoU: \",Train_MIoU)\n",
    "    print(\"Validation Loss: \",Val_Loss)\n",
    "    print(\"Validation MIoU: \",Val_MIoU)\n",
    "    print(\"Test Loss: \",Test_loss)\n",
    "    print(\"Test MIoU: \",Test_MIoU)\n",
    "    print(\"Total Epochs: \",total_epochs)\n",
    "\n",
    "    #  Save Best Model Weights\n",
    "    file_path = os.getcwd()+'/models/CityScape_Train_KITTI_Val/batchsize tuning/best_batchsize_model_weight.weights.h5'\n",
    "    model_list[index_of_best_model].save_weights(file_path)\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/CityScape_Train_KITTI_Val/batchsize tuning/results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Batch Size: {best_batch_size}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        file.write(f\"Total Epochs: {total_epochs}\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"Results already stored in file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Tuning of Neural Network Dropout Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new folders\n",
    "\n",
    "!cd models/CityScape_Train_KITTI_Val && mkdir \"dropout tuning\"\n",
    "!cd models/CityScape_Train_KITTI_Val/\"dropout tuning\" && mkdir weights\n",
    "\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/dropout tuning/results.txt\"):\n",
    "    model_list = []\n",
    "    train_miou_list = []\n",
    "    valid_miou_list = []\n",
    "    test_miou_list = []\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    test_loss_list = []\n",
    "    learning_rate_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    #Validation Dataset Creation\n",
    "    validation_dataset = create_dataset(validation_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    #Test Dataset\n",
    "    test_dataset = create_dataset(test_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    for dropout in dropout_list:\n",
    "\n",
    "        print(\"Model with dropout = \", dropout)\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    best_batch_size)\n",
    "\n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "\n",
    "        model_list.append(model)\n",
    "\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        # Save Model Weights\n",
    "        file_path = 'models/CityScape_Train_KITTI_Val/dropout tuning/weights/'+'dropout_'+str(dropout_list[index])+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Hyper Parameter Tuning already performed. Skipping execution of cell\")\n",
    "    with open(os.getcwd()+'/models/CityScape_Train_KITTI_Val/dropout tuning/results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Dropout'):\n",
    "                best_dropout = float(line.split(':')[-1].strip())\n",
    "\n",
    "    print(\"Best Dropout: \",best_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/dropout tuning/dropout_vs_Loss.jpg\"):\n",
    "    plot_loss_data(dropout_list)\n",
    "    plot.xlabel('Dropout')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Dropout vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/dropout tuning/dropout_vs_Loss.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/dropout tuning/dropout_vs_Loss.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/dropout tuning/dropout_vs_MIoU.jpg\"):\n",
    "    plot_miou_data(dropout_list)\n",
    "    plot.xlabel('Dropout')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Dropout vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/dropout tuning/dropout_vs_MIoU.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/dropout tuning/dropout_vs_MIoU.jpg\")\n",
    "    \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/dropout tuning/results.txt\"):\n",
    "    best_valid_loss = 100\n",
    "    index = 0\n",
    "\n",
    "    while index < len(model_list):\n",
    "        if valid_loss_list[index] < best_valid_loss:\n",
    "            index_of_best_model = index\n",
    "            best_valid_loss = valid_loss_list[index]\n",
    "        index += 1\n",
    "\n",
    "    best_model = model_list[index_of_best_model]\n",
    "    best_dropout = dropout_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    Train_Loss = train_loss_list[index_of_best_model]\n",
    "    Train_MIoU = train_miou_list[index_of_best_model]\n",
    "    Val_Loss = valid_loss_list[index_of_best_model]\n",
    "    Val_MIoU = valid_miou_list[index_of_best_model]\n",
    "    Test_loss = test_loss_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    total_epochs = epoch_list[index_of_best_model]\n",
    "\n",
    "    print(\"Best Dropout: \",best_dropout)\n",
    "    print(\"Training Loss: \",Train_Loss)\n",
    "    print(\"Training MIoU: \",Train_MIoU)\n",
    "    print(\"Validation Loss: \",Val_Loss)\n",
    "    print(\"Validation MIoU: \",Val_MIoU)\n",
    "    print(\"Test Loss: \",Test_loss)\n",
    "    print(\"Test MIoU: \",Test_MIoU)\n",
    "    print(\"Total Epochs: \",total_epochs)\n",
    "\n",
    "    #  Save Best Model Weights\n",
    "    file_path = os.getcwd()+'/models/CityScape_Train_KITTI_Val/dropout tuning/best_dropout_model_weight.weights.h5'\n",
    "    model_list[index_of_best_model].save_weights(file_path)\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/CityScape_Train_KITTI_Val/dropout tuning/results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Dropout: {best_dropout}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        file.write(f\"Total Epochs: {total_epochs}\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"Results already stored in file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Tuning Neural Network Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new folders\n",
    "\n",
    "!cd models/CityScape_Train_KITTI_Val && mkdir \"weight_decay tuning\"\n",
    "!cd models/CityScape_Train_KITTI_Val/\"weight_decay tuning\" && mkdir weights\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/weight_decay tuning/results.txt\"):\n",
    "    model_list = []\n",
    "    train_miou_list = []\n",
    "    valid_miou_list = []\n",
    "    test_miou_list = []\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    test_loss_list = []\n",
    "    learning_rate_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    #Validation Dataset Creation\n",
    "    validation_dataset = create_dataset(validation_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    #Test Dataset\n",
    "    test_dataset = create_dataset(test_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "    \n",
    "    for weight_decay in weight_decay_list:\n",
    "\n",
    "        print(\"Model with weight_decay = \", weight_decay)\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, best_dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    best_batch_size)\n",
    "\n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "\n",
    "        model_list.append(model)\n",
    "\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        # Save Model Weights\n",
    "        file_path = 'models/CityScape_Train_KITTI_Val/weight_decay tuning/weights/'+'weight_decay_'+str(weight_decay_list[index])+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Hyper Parameter Tuning already performed. Skipping execution of cell\")\n",
    "    with open(os.getcwd()+'/models/CityScape_Train_KITTI_Val/weight_decay tuning/results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Weight Decay'):\n",
    "                best_weight_decay = float(line.split(':')[-1].strip())\n",
    "\n",
    "    print(\"Best Weight Decay: \",best_weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/weight_decay tuning/weight_decay_vs_Loss.jpg\"):\n",
    "    plot_loss_data(weight_decay_list)\n",
    "    plot.xscale('log')\n",
    "    plot.xlabel('Weight Decay')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Weight Decay vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/weight_decay tuning/weight_decay_vs_Loss.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/weight_decay tuning/weight_decay_vs_Loss.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/weight_decay tuning/weight_decay_vs_MIoU.jpg\"):\n",
    "    plot_miou_data(weight_decay_list)\n",
    "    plot.xscale('log')\n",
    "    plot.xlabel('Weight Decay')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Weight Decay vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/weight_decay tuning/weight_decay_vs_MIoU.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/weight_decay tuning/weight_decay_vs_MIoU.jpg\")\n",
    "                       \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/weight_decay tuning/results.txt\"):\n",
    "    best_test_loss = 100\n",
    "    index = 0\n",
    "\n",
    "    while index < len(model_list):\n",
    "        if valid_loss_list[index] < best_valid_loss:\n",
    "            index_of_best_model = index\n",
    "            best_valid_loss = valid_loss_list[index]\n",
    "        index += 1\n",
    "\n",
    "    best_model = model_list[index_of_best_model]\n",
    "    best_weight_decay = weight_decay_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    Train_Loss = train_loss_list[index_of_best_model]\n",
    "    Train_MIoU = train_miou_list[index_of_best_model]\n",
    "    Val_Loss = valid_loss_list[index_of_best_model]\n",
    "    Val_MIoU = valid_miou_list[index_of_best_model]\n",
    "    Test_loss = test_loss_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    total_epochs = epoch_list[index_of_best_model]\n",
    "\n",
    "    print(\"Best Weight Decay: \",best_weight_decay)\n",
    "    print(\"Training Loss: \",Train_Loss)\n",
    "    print(\"Training MIoU: \",Train_MIoU)\n",
    "    print(\"Validation Loss: \",Val_Loss)\n",
    "    print(\"Validation MIoU: \",Val_MIoU)\n",
    "    print(\"Test Loss: \",Test_loss)\n",
    "    print(\"Test MIoU: \",Test_MIoU)\n",
    "    print(\"Total Epochs: \",total_epochs)\n",
    "\n",
    "    #  Save Best Model Weights\n",
    "    file_path = os.getcwd()+'/models/CityScape_Train_KITTI_Val/weight_decay tuning/best_weight_decay_model_weight.weights.h5'\n",
    "    model_list[index_of_best_model].save_weights(file_path)\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/CityScape_Train_KITTI_Val/weight_decay tuning/results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Weight Decay: {best_weight_decay}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        file.write(f\"Total Epochs: {total_epochs}\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"Results already stored in file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd models/CityScape_Train_KITTI_Val && mkdir augmentations\n",
    "!cd models/CityScape_Train_KITTI_Val/augmentations && mkdir weights\n",
    "!cd models/CityScape_Train_KITTI_Val/augmentations && mkdir graphs \n",
    "\n",
    "training_image_label_pairs = CityScape_subset_training_image_label_pairs\n",
    "validation_image_label_pairs = KITTI_validation_image_label_pairs\n",
    "test_image_label_pairs = ika_test_image_label_pairs\n",
    "\n",
    "# Tuned Hyper Parameters\n",
    "udepth = 5\n",
    "filters1 = 16\n",
    "dropout = 0\n",
    "weight_decay = 0.000001\n",
    "batch_size = 4\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "activation = tf.nn.relu\n",
    "\n",
    "#Validation Dataset Creation\n",
    "validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "print(\"Validation Dataset Length:\", tf.data.experimental.cardinality(validation_dataset).numpy())\n",
    "\n",
    "#ika Test Dataset\n",
    "test_dataset = create_dataset(ika_test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "print(\"Test Dataset Length:\", tf.data.experimental.cardinality(test_dataset).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Individual Augmentations\n",
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/Loss_single.jpg\"):\n",
    "            \n",
    "    flip_prob = zoom_prob = light_prob = noise_prob = 0\n",
    "    prob_list = [0,0,0,0]\n",
    "    prob_name = [\" Flip \", \" Zoom \", \" Lighting \", \" Noise \"]\n",
    "            \n",
    "\n",
    "    model_list = []\n",
    "    aug_names_list = []\n",
    "    train_miou_list = []\n",
    "    valid_miou_list = []\n",
    "    test_miou_list = []\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    test_loss_list = []\n",
    "    learning_rate_list = []\n",
    "    model_processing_time = []\n",
    "    epoch_list = []\n",
    "\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for prob in range(len(prob_list)):\n",
    "    \n",
    "        prob_list = [0] * len(prob_list)\n",
    "        \n",
    "        prob_list[prob] = 1\n",
    "\n",
    "        flip_prob = prob_list[0]\n",
    "        zoom_prob = prob_list[1]\n",
    "        light_prob = prob_list[2]\n",
    "        noise_prob = prob_list[3]\n",
    "        \n",
    "        aug_list = [flip_prob, zoom_prob, light_prob, noise_prob]\n",
    "        file_name = ''\n",
    "        \n",
    "        for augment in range(len(aug_list)):\n",
    "            \n",
    "            if aug_list[augment] == 1:\n",
    "                \n",
    "                file_name = file_name + str(prob_name[augment])\n",
    "            \n",
    "        print(\"Model augmented with:\", file_name)\n",
    "    \n",
    "    \n",
    "        print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "        print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size)\n",
    "        \n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "        model_list.append(model)\n",
    "        aug_names_list.append(file_name)\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        file_path = os.getcwd()+'/models/CityScape_Train_KITTI_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Augmentations already performed. Skipping execution of cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/Loss_single.jpg\"):\n",
    "    plot_loss_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Augmentations vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/Loss_single.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/Loss_single.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/MIoU_single.jpg\"):\n",
    "    plot_miou_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Augmentations vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/MIoU_single.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/MIoU_single.jpg\")\n",
    "                       \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/Loss_double.jpg\"):\n",
    "    \n",
    "    \n",
    "    #In combination with Flip\n",
    "    flip_prob = 1\n",
    "    zoom_prob = light_prob = noise_prob = 0\n",
    "    prob_list = [0,0,0] \n",
    "    prob_name = [\" Flip \", \" Zoom \", \" Lighting \", \" Noise \"]\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for prob in range(len(prob_list)):\n",
    "    \n",
    "        prob_list = [0] * len(prob_list)\n",
    "        \n",
    "        prob_list[prob] = 1\n",
    "\n",
    "        zoom_prob = prob_list[0]\n",
    "        light_prob = prob_list[1]\n",
    "        noise_prob = prob_list[2]\n",
    "        \n",
    "        aug_list = [flip_prob, zoom_prob, light_prob, noise_prob]\n",
    "        file_name = ''\n",
    "        \n",
    "        for augment in range(len(aug_list)):\n",
    "            \n",
    "            if aug_list[augment] == 1:\n",
    "                \n",
    "                file_name = file_name + str(prob_name[augment])\n",
    "            \n",
    "        print(\"Model augmented with:\", file_name)\n",
    "    \n",
    "    \n",
    "        print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "        print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size)\n",
    "        \n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "        model_list.append(model)\n",
    "        aug_names_list.append(file_name)\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        file_path = os.getcwd()+'/models/CityScape_Train_KITTI_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Augmentations already performed. Skipping execution of cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/Loss_double.jpg\"):\n",
    "    plot_loss_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Augmentations vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/Loss_double.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/Loss_double.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/MIoU_double.jpg\"):\n",
    "    plot_miou_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Augmentations vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/MIoU_double.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/MIoU_double.jpg\")\n",
    "                       \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/Loss_final.jpg\"):\n",
    "    \n",
    "    #In combination with Flip and Zoom\n",
    "    flip_prob = zoom_prob = 1\n",
    "    light_prob = noise_prob = 0\n",
    "    prob_list = [0,0] \n",
    "    prob_name = [\" Flip \", \" Zoom \", \" Lighting \", \" Noise \"]\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for prob in range(len(prob_list)):\n",
    "\n",
    "        prob_list = [0] * len(prob_list)\n",
    "\n",
    "        prob_list[prob] = 1\n",
    "\n",
    "        light_prob = prob_list[0]\n",
    "        noise_prob = prob_list[1]\n",
    "        \n",
    "        aug_list = [flip_prob, zoom_prob, light_prob, noise_prob]\n",
    "        file_name = ''\n",
    "        \n",
    "        for augment in range(len(aug_list)):\n",
    "            \n",
    "            if aug_list[augment] == 1:\n",
    "                \n",
    "                file_name = file_name + str(prob_name[augment])\n",
    "            \n",
    "        print(\"Model augmented with:\", file_name)\n",
    "    \n",
    "    \n",
    "        print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "        print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size)\n",
    "        \n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "        model_list.append(model)\n",
    "        aug_names_list.append(file_name)\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        file_path = os.getcwd()+'/models/CityScape_Train_KITTI_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    #All augmentations\n",
    "    noise_prob = flip_prob = light_prob = zoom_prob = 1\n",
    "    file_name = 'All augments'\n",
    "\n",
    "    print(\"Model augmented with:\", file_name)\n",
    "    print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "\n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "    print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "    model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                activation, dropout, weight_decay, \n",
    "                                                                                                training_dataset, validation_dataset, \n",
    "                                                                                                batch_size)\n",
    "\n",
    "    test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "    model_list.append(model)\n",
    "    aug_names_list.append(file_name)\n",
    "    train_miou_list.append(train_miou[best_epoch-1])\n",
    "    train_loss_list.append(train_loss[best_epoch-1])\n",
    "    valid_miou_list.append(val_miou[best_epoch-1])\n",
    "    valid_loss_list.append(val_loss[best_epoch-1])\n",
    "    test_miou_list.append(test_miou)\n",
    "    test_loss_list.append(test_loss)\n",
    "    learning_rate_list.append(best_learning_rate)\n",
    "    epoch_list.append((best_epoch + 10))\n",
    "\n",
    "    file_path = os.getcwd()+'/models/KITTI_Train_CityScape_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "    model_list[index].save_weights(file_path)\n",
    "    index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Augmentations already performed. Skipping execution of cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/Loss_final.jpg\"):\n",
    "    plot_loss_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Augmentations vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/Loss_final.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/Loss_final.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/MIoU_final.jpg\"):\n",
    "    plot_miou_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Augmentations vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/MIoU_final.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/graphs/MIoU_final.jpg\")\n",
    "                       \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/augmentations/results.txt\"):\n",
    "    best_valid_loss = 100\n",
    "    index = 0\n",
    "\n",
    "    while index < len(model_list):\n",
    "        if valid_loss_list[index] < best_valid_loss:\n",
    "            index_of_best_model = index\n",
    "            best_valid_loss = valid_loss_list[index]\n",
    "        index += 1\n",
    "\n",
    "    best_model = model_list[index_of_best_model]\n",
    "    best_augmentation = aug_names_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    Train_Loss = train_loss_list[index_of_best_model]\n",
    "    Train_MIoU = train_miou_list[index_of_best_model]\n",
    "    Val_Loss = valid_loss_list[index_of_best_model]\n",
    "    Val_MIoU = valid_miou_list[index_of_best_model]\n",
    "    Test_loss = test_loss_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "\n",
    "    print(\"Best Augmentation: \",best_augmentation)\n",
    "    print(\"Training Loss: \",Train_Loss)\n",
    "    print(\"Training MIoU: \",Train_MIoU)\n",
    "    print(\"Validation Loss: \",Val_Loss)\n",
    "    print(\"Validation MIoU: \",Val_MIoU)\n",
    "    print(\"Test Loss: \",Test_loss)\n",
    "    print(\"Test MIoU: \",Test_MIoU)\n",
    "\n",
    "    #  Save Best Model Weights\n",
    "    file_path = os.getcwd()+'/models/CityScape_Train_KITTI_Val/augmentations/best_augmentation_model_weight.weights.h5'\n",
    "    model_list[index_of_best_model].save_weights(file_path)\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/CityScape_Train_KITTI_Val/augmentations/results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Augmentation: {best_augmentation}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"Results already stored in file\")\n",
    "    with open(os.getcwd()+'/models/CityScape_Train_KITTI_Val/augmentations/results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Augmentation'):\n",
    "                best_aug = str(line.split(':')[-1].strip())\n",
    "\n",
    "    print(\"Best Augmentation: \",best_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merged Training Dataset and Merged Validation Dataset\n",
    "\n",
    "Finally, the merged training and validation datasets are used. In the grid search the models are trained only up to 10 epochs due to the large size of the datasets. Once again, the same process flow is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd models && mkdir Merged_Train_Merged_Val\n",
    "\n",
    "training_image_label_pairs = merged_training_image_label_pairs\n",
    "validation_image_label_pairs = merged_validation_image_label_pairs\n",
    "test_image_label_pairs = ika_test_image_label_pairs\n",
    "\n",
    "# Base Model Hyper Parameters\n",
    "dropout = 0.1\n",
    "weight_decay = 0\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell to test model training for the examiner\n",
    "\n",
    "training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "#Validation Dataset Creation\n",
    "validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "print(\"Validation Dataset Length:\", tf.data.experimental.cardinality(validation_dataset).numpy())\n",
    "\n",
    "#Test Dataset\n",
    "test_dataset = create_dataset(test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "#Training base model\n",
    "model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate = CNN_model(num_classes, udepth, filters1, kernel_size, activation, dropout, weight_decay, training_dataset, validation_dataset, batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged-Merged Dataset Base Model\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/Merged_Merged_Base_Model.weights.h5\"):\n",
    "        \n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "    print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "    #Validation Dataset Creation\n",
    "    validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "    print(\"Validation Dataset Length:\", tf.data.experimental.cardinality(validation_dataset).numpy())\n",
    "\n",
    "    #Test Dataset\n",
    "    test_dataset = create_dataset(test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "    model = getModel(input_shape=(368, 1248, 3),\n",
    "                num_classes=num_classes,\n",
    "                udepth=udepth,\n",
    "                filters1=filters1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation,\n",
    "                batch_norm=True,\n",
    "                dropout=dropout,\n",
    "                l2_weight_decay=weight_decay)\n",
    "\n",
    "    # Model Compiling\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=[SparseMeanIoU(num_classes=num_classes, name=\"MIoU\")])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    best_metrics_callback = BestMetricsCallback()\n",
    "\n",
    "    # Model Training\n",
    "    history = model.fit(training_dataset, \n",
    "                    validation_data = validation_dataset, \n",
    "                    epochs = 1000, \n",
    "                    callbacks=[early_stopping, best_metrics_callback],\n",
    "                    batch_size = batch_size,\n",
    "                    verbose = 1\n",
    "                    )\n",
    "    \n",
    "    best_epoch = best_metrics_callback.best_epoch\n",
    "    train_miou = history.history.get('MIoU')\n",
    "    train_loss = history.history.get('loss')\n",
    "    val_miou = history.history.get('val_MIoU')\n",
    "    val_loss = history.history.get('val_loss') \n",
    "    \n",
    "    test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "\n",
    "    print(\"Best learning rate: \",best_learning_rate)\n",
    "    print(\"Training Loss: \",train_loss[best_epoch-1])\n",
    "    print(\"Training MIoU: \",train_miou[best_epoch-1])\n",
    "    print(\"Validation Loss: \",val_loss[best_epoch-1])\n",
    "    print(\"Validation MIoU: \",val_miou[best_epoch-1])\n",
    "    print(\"Test Loss: \",test_loss)\n",
    "    print(\"Test MIoU: \",test_miou)\n",
    "    print(\"Total Epochs: \",(best_epoch + 10))\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/Merged_Train_Merged_Val/Merged_Merged_Base_Model_results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Training Loss: {train_loss[best_epoch-1]}\\n\")\n",
    "        file.write(f\"Training MIoU: {train_miou[best_epoch-1]}\\n\")\n",
    "        file.write(f\"Validation Loss: {val_loss[best_epoch-1]}\\n\")\n",
    "        file.write(f\"Validation MIoU: {val_miou[best_epoch-1]}\\n\")\n",
    "        file.write(f\"Test Loss: {test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {test_miou}\\n\")\n",
    "        file.write(f\"Total Epochs: {best_epoch+10}\\n\")\n",
    "    # Save Model\n",
    "    model.save_weights(os.getcwd()+\"/models/Merged_Train_Merged_Val/Merged_Merged_Base_Model.weights.h5\")\n",
    "\n",
    "else:\n",
    "    \n",
    "    print(\"Base Model already trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Model_3 = getModel(input_shape=(368, 1248, 3),\n",
    "                num_classes = num_classes,\n",
    "                udepth = udepth,\n",
    "                filters1 = filters1,\n",
    "                kernel_size = kernel_size,\n",
    "                activation = activation,\n",
    "                batch_norm=True,\n",
    "                dropout = dropout,\n",
    "                l2_weight_decay = weight_decay)\n",
    "with open(os.getcwd()+'/models/Merged_Train_Merged_Val/Merged_Merged_Base_Model_results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best learning rate'):\n",
    "                best_learning_rate = float(line.split(':')[-1].strip())\n",
    "Base_Model_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_learning_rate),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[SparseMeanIoU(num_classes=num_classes, name=\"MIoU\")])\n",
    "Base_Model_3.load_weights(os.getcwd()+'/models/Merged_Train_Merged_Val/Merged_Merged_Base_Model.weights.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Tuning Batch Size of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new folders\n",
    "\n",
    "!cd models/Merged_Train_Merged_Val && mkdir \"batchsize tuning\"\n",
    "!cd models/Merged_Train_Merged_Val/\"batchsize tuning\" && mkdir weights\n",
    "\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/batchsize tuning/results.txt\"):\n",
    "    model_list = []\n",
    "    train_miou_list = []\n",
    "    valid_miou_list = []\n",
    "    test_miou_list = []\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    test_loss_list = []\n",
    "    learning_rate_list = []\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for batch_size in batch_size_list:\n",
    "\n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "        #Validation Dataset Creation\n",
    "        validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "        #Test Dataset\n",
    "        test_dataset = create_dataset(test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "        \n",
    "        print(\"Model with batch size = \", batch_size)\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size, epochs = 10)\n",
    "\n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "\n",
    "        model_list.append(model)\n",
    "\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "\n",
    "        # Save Model Weights\n",
    "        file_path = 'models/Merged_Train_Merged_Val/batchsize tuning/weights/'+'batchsize_'+str(batch_size_list[index])+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Hyper Parameter Tuning already performed. Skipping execution of cell\")\n",
    "    with open(os.getcwd()+'/models/Merged_Train_Merged_Val/batchsize tuning/results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Batch Size'):\n",
    "                best_batch_size = int(line.split(':')[-1].strip())\n",
    "\n",
    "    print(\"Best Batch Size: \",best_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/batchsize tuning/batch_size_vs_Loss.jpg\"):\n",
    "    plot_loss_data(batch_size_list)\n",
    "    plot.xlabel('Batch Size')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Batch Size vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/batchsize tuning/batch_size_vs_Loss.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+'/models/Merged_Train_Merged_Val/batchsize tuning/batch_size_vs_Loss.jpg')\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/batchsize tuning/batch_size_vs_MIoU.jpg\"):\n",
    "    plot_miou_data(batch_size_list)\n",
    "    plot.xlabel('Batch Size')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Batch Size vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/batchsize tuning/batch_size_vs_MIoU.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/batchsize tuning/batch_size_vs_MIoU.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/batchsize tuning/results.txt\"):\n",
    "    best_valid_loss = 100\n",
    "    index = 0\n",
    "\n",
    "    while index < len(model_list):\n",
    "        if valid_loss_list[index] < best_valid_loss:\n",
    "            index_of_best_model = index\n",
    "            best_valid_loss = valid_loss_list[index]\n",
    "        index += 1\n",
    "\n",
    "    best_model = model_list[index_of_best_model]\n",
    "    best_batch_size = batch_size_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    Train_Loss = train_loss_list[index_of_best_model]\n",
    "    Train_MIoU = train_miou_list[index_of_best_model]\n",
    "    Val_Loss = valid_loss_list[index_of_best_model]\n",
    "    Val_MIoU = valid_miou_list[index_of_best_model]\n",
    "    Test_loss = test_loss_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "\n",
    "    print(\"Best Batch Size: \",best_batch_size)\n",
    "    print(\"Training Loss: \",Train_Loss)\n",
    "    print(\"Training MIoU: \",Train_MIoU)\n",
    "    print(\"Validation Loss: \",Val_Loss)\n",
    "    print(\"Validation MIoU: \",Val_MIoU)\n",
    "    print(\"Test Loss: \",Test_loss)\n",
    "    print(\"Test MIoU: \",Test_MIoU)\n",
    "\n",
    "    #  Save Best Model Weights\n",
    "    file_path = os.getcwd()+'/models/Merged_Train_Merged_Val/batchsize tuning/best_batchsize_model_weight.weights.h5'\n",
    "    model_list[index_of_best_model].save_weights(file_path)\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/Merged_Train_Merged_Val/batchsize tuning/results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Batch Size: {best_batch_size}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"Results already stored in file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Tuning of Neural Network Dropout Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new folders\n",
    "\n",
    "!cd models/Merged_Train_Merged_Val && mkdir \"dropout tuning\"\n",
    "!cd models/Merged_Train_Merged_Val/\"dropout tuning\" && mkdir weights\n",
    "\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/dropout tuning/results.txt\"):\n",
    "    model_list = []\n",
    "    train_miou_list = []\n",
    "    valid_miou_list = []\n",
    "    test_miou_list = []\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    test_loss_list = []\n",
    "    learning_rate_list = []\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    #Validation Dataset Creation\n",
    "    validation_dataset = create_dataset(validation_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    #Test Dataset\n",
    "    test_dataset = create_dataset(test_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    for dropout in dropout_list:\n",
    "\n",
    "        print(\"Model with dropout = \", dropout)\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    best_batch_size, epochs = 10)\n",
    "\n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "\n",
    "        model_list.append(model)\n",
    "\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "\n",
    "        # Save Model Weights\n",
    "        file_path = 'models/Merged_Train_Merged_Val/dropout tuning/weights/'+'dropout_'+str(dropout_list[index])+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Hyper Parameter Tuning already performed. Skipping execution of cell\")\n",
    "    with open(os.getcwd()+'/models/Merged_Train_Merged_Val/dropout tuning/results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Dropout'):\n",
    "                best_dropout = float(line.split(':')[-1].strip())\n",
    "\n",
    "    print(\"Best Dropout: \",best_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/dropout tuning/dropout_vs_Loss.jpg\"):\n",
    "    plot_loss_data(dropout_list)\n",
    "    plot.xlabel('Dropout')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Dropout vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/dropout tuning/dropout_vs_Loss.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/dropout tuning/dropout_vs_Loss.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/dropout tuning/dropout_vs_MIoU.jpg\"):\n",
    "    plot_miou_data(dropout_list)\n",
    "    plot.xlabel('Dropout')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Dropout vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/dropout tuning/dropout_vs_MIoU.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/dropout tuning/dropout_vs_MIoU.jpg\")\n",
    "    \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/dropout tuning/results.txt\"):\n",
    "    best_valid_loss = 100\n",
    "    index = 0\n",
    "\n",
    "    while index < len(model_list):\n",
    "        if valid_loss_list[index] < best_valid_loss:\n",
    "            index_of_best_model = index\n",
    "            best_valid_loss = valid_loss_list[index]\n",
    "        index += 1\n",
    "\n",
    "    best_model = model_list[index_of_best_model]\n",
    "    best_dropout = dropout_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    Train_Loss = train_loss_list[index_of_best_model]\n",
    "    Train_MIoU = train_miou_list[index_of_best_model]\n",
    "    Val_Loss = valid_loss_list[index_of_best_model]\n",
    "    Val_MIoU = valid_miou_list[index_of_best_model]\n",
    "    Test_loss = test_loss_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "\n",
    "    print(\"Best Dropout: \",best_dropout)\n",
    "    print(\"Training Loss: \",Train_Loss)\n",
    "    print(\"Training MIoU: \",Train_MIoU)\n",
    "    print(\"Validation Loss: \",Val_Loss)\n",
    "    print(\"Validation MIoU: \",Val_MIoU)\n",
    "    print(\"Test Loss: \",Test_loss)\n",
    "    print(\"Test MIoU: \",Test_MIoU)\n",
    "\n",
    "    #  Save Best Model Weights\n",
    "    file_path = os.getcwd()+'/models/Merged_Train_Merged_Val/dropout tuning/best_dropout_model_weight.weights.h5'\n",
    "    model_list[index_of_best_model].save_weights(file_path)\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/Merged_Train_Merged_Val/dropout tuning/results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Dropout: {best_dropout}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"Results already stored in file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Neural Network Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new folders\n",
    "\n",
    "!cd models/Merged_Train_Merged_Val && mkdir \"weight_decay tuning\"\n",
    "!cd models/Merged_Train_Merged_Val/\"weight_decay tuning\" && mkdir weights\n",
    "\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/weight_decay tuning/results.txt\"):\n",
    "    model_list = []\n",
    "    train_miou_list = []\n",
    "    valid_miou_list = []\n",
    "    test_miou_list = []\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    test_loss_list = []\n",
    "    learning_rate_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    #Validation Dataset Creation\n",
    "    validation_dataset = create_dataset(validation_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "\n",
    "    #Test Dataset\n",
    "    test_dataset = create_dataset(test_image_label_pairs, batch_size = best_batch_size,do_augmentation = False)\n",
    "    \n",
    "    for weight_decay in weight_decay_list:\n",
    "\n",
    "        print(\"Model with weight_decay = \", weight_decay)\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, best_dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    best_batch_size, epochs = 10)\n",
    "\n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "\n",
    "        model_list.append(model)\n",
    "\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        # Save Model Weights\n",
    "        file_path = 'models/Merged_Train_Merged_Val/weight_decay tuning/weights/'+'weight_decay_'+str(weight_decay_list[index])+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Hyper Parameter Tuning already performed. Skipping execution of cell\")\n",
    "    with open(os.getcwd()+'/models/Merged_Train_Merged_Val/weight_decay tuning/results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Weight Decay'):\n",
    "                best_weight_decay = float(line.split(':')[-1].strip())\n",
    "\n",
    "    print(\"Best Weight Decay: \",best_weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/weight_decay tuning/weight_decay_vs_Loss.jpg\"):\n",
    "    plot_loss_data(weight_decay_list)\n",
    "    plot.xscale('log')\n",
    "    plot.xlabel('Weight Decay')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Weight Decay vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/weight_decay tuning/weight_decay_vs_Loss.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/weight_decay tuning/weight_decay_vs_Loss.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/weight_decay tuning/weight_decay_vs_MIoU.jpg\"):\n",
    "    plot_miou_data(weight_decay_list)\n",
    "    plot.xscale('log')\n",
    "    plot.xlabel('Weight Decay')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Weight Decay vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/weight_decay tuning/weight_decay_vs_MIoU.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/weight_decay tuning/weight_decay_vs_MIoU.jpg\")\n",
    "                       \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/weight_decay tuning/results.txt\"):\n",
    "    best_valid_loss = 100\n",
    "    index = 0\n",
    "\n",
    "    while index < len(model_list):\n",
    "        if valid_loss_list[index] < best_valid_loss:\n",
    "            index_of_best_model = index\n",
    "            best_valid_loss = valid_loss_list[index]\n",
    "        index += 1\n",
    "\n",
    "    best_model = model_list[index_of_best_model]\n",
    "    best_weight_decay = weight_decay_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    Train_Loss = train_loss_list[index_of_best_model]\n",
    "    Train_MIoU = train_miou_list[index_of_best_model]\n",
    "    Val_Loss = valid_loss_list[index_of_best_model]\n",
    "    Val_MIoU = valid_miou_list[index_of_best_model]\n",
    "    Test_loss = test_loss_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "\n",
    "    print(\"Best Weight Decay: \",best_weight_decay)\n",
    "    print(\"Training Loss: \",Train_Loss)\n",
    "    print(\"Training MIoU: \",Train_MIoU)\n",
    "    print(\"Validation Loss: \",Val_Loss)\n",
    "    print(\"Validation MIoU: \",Val_MIoU)\n",
    "    print(\"Test Loss: \",Test_loss)\n",
    "    print(\"Test MIoU: \",Test_MIoU)\n",
    "\n",
    "    #  Save Best Model Weights\n",
    "    file_path = os.getcwd()+'/models/Merged_Train_Merged_Val/weight_decay tuning/best_weight_decay_model_weight.weights.h5'\n",
    "    model_list[index_of_best_model].save_weights(file_path)\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/Merged_Train_Merged_Val/weight_decay tuning/results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Weight Decay: {best_weight_decay}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"Results already stored in file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd models && mkdir Merged_Train_Merged_Val\n",
    "!cd models/Merged_Train_Merged_Val && mkdir augmentations\n",
    "!cd models/Merged_Train_Merged_Val/augmentations && mkdir weights\n",
    "!cd models/Merged_Train_Merged_Val/augmentations && mkdir graphs \n",
    "\n",
    "training_image_label_pairs = merged_training_image_label_pairs\n",
    "validation_image_label_pairs = merged_validation_image_label_pairs\n",
    "test_image_label_pairs = ika_test_image_label_pairs\n",
    "\n",
    "# Tuned Hyper Parameters\n",
    "udepth = 5\n",
    "filters1 = 16\n",
    "dropout = 0.1\n",
    "weight_decay = 0.0000001\n",
    "batch_size = 6\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "activation = tf.nn.relu\n",
    "\n",
    "#Validation Dataset Creation\n",
    "validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "print(\"Validation Dataset Length:\", tf.data.experimental.cardinality(validation_dataset).numpy())\n",
    "\n",
    "#ika Test Dataset\n",
    "test_dataset = create_dataset(ika_test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "print(\"Test Dataset Length:\", tf.data.experimental.cardinality(test_dataset).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/Loss_single.jpg\"):\n",
    "            \n",
    "    flip_prob = zoom_prob = light_prob = noise_prob = 0\n",
    "    prob_list = [0,0,0,0]\n",
    "    prob_name = [\" Flip \", \" Zoom \", \" Lighting \", \" Noise \"]\n",
    "            \n",
    "\n",
    "    model_list = []\n",
    "    aug_names_list = []\n",
    "    train_miou_list = []\n",
    "    valid_miou_list = []\n",
    "    test_miou_list = []\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    test_loss_list = []\n",
    "    learning_rate_list = []\n",
    "    model_processing_time = []\n",
    "    epoch_list = []\n",
    "\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for prob in range(len(prob_list)):\n",
    "    \n",
    "        prob_list = [0] * len(prob_list)\n",
    "        \n",
    "        prob_list[prob] = 1\n",
    "\n",
    "        flip_prob = prob_list[0]\n",
    "        zoom_prob = prob_list[1]\n",
    "        light_prob = prob_list[2]\n",
    "        noise_prob = prob_list[3]\n",
    "        \n",
    "        aug_list = [flip_prob, zoom_prob, light_prob, noise_prob]\n",
    "        file_name = ''\n",
    "        \n",
    "        for augment in range(len(aug_list)):\n",
    "            \n",
    "            if aug_list[augment] == 1:\n",
    "                \n",
    "                file_name = file_name + str(prob_name[augment])\n",
    "            \n",
    "        print(\"Model augmented with:\", file_name)        \n",
    "    \n",
    "        print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "        \n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "        print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size, epochs = 10)\n",
    "        \n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "        model_list.append(model)\n",
    "        aug_names_list.append(file_name)\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        file_path = os.getcwd()+'/models/Merged_Train_Merged_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Augmentations already performed. Skipping execution of cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/Loss_single.jpg\"):\n",
    "    plot_loss_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Augmentations vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/Loss_single.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/Loss_single.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/MIoU_single.jpg\"):\n",
    "    plot_miou_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Augmentations vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/MIoU_single.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/MIoU_single.jpg\")\n",
    "                       \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/Loss_double.jpg\"):\n",
    "    \n",
    "    \n",
    "    #In combination with Lighting\n",
    "    light_prob = 1\n",
    "    flip_prob = zoom_prob = noise_prob = 0\n",
    "    prob_list = [0,0,0] \n",
    "    prob_name = [\" Flip \", \" Zoom \", \" Lighting \", \" Noise \"]\n",
    "\n",
    "    index = 0\n",
    "    \n",
    "    for prob in range(len(prob_list)):\n",
    "    \n",
    "        prob_list = [0] * len(prob_list)\n",
    "        \n",
    "        prob_list[prob] = 1\n",
    "\n",
    "        flip_prob = prob_list[0]\n",
    "        zoom_prob = prob_list[1]\n",
    "        noise_prob = prob_list[2]\n",
    "        \n",
    "        aug_list = [flip_prob, zoom_prob, light_prob, noise_prob]\n",
    "        file_name = ''\n",
    "        \n",
    "        for augment in range(len(aug_list)):\n",
    "            \n",
    "            if aug_list[augment] == 1:\n",
    "                \n",
    "                file_name = file_name + str(prob_name[augment])\n",
    "            \n",
    "        print(\"Model augmented with:\", file_name)\n",
    "    \n",
    "    \n",
    "        print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "    \n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "        print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size, epochs = 10)\n",
    "\n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "        model_list.append(model)\n",
    "        aug_names_list.append(file_name)\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        file_path = os.getcwd()+'/models/Merged_Train_Merged_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "\n",
    "else:\n",
    "    print(\"Augmentations already performed. Skipping execution of cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/Loss_double.jpg\"):\n",
    "    plot_loss_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Augmentations vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/Loss_double.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/Loss_double.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/MIoU_double.jpg\"):\n",
    "    plot_miou_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Augmentations vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/MIoU_double.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/MIoU_double.jpg\")\n",
    "                       \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/Loss_final.jpg\"):\n",
    "    \n",
    "    \n",
    "    #In combination with Flip and Lighting\n",
    "    flip_prob = light_prob = 1\n",
    "    zoom_prob = noise_prob = 0\n",
    "    prob_list = [0,0] \n",
    "    prob_name = [\" Flip \", \" Zoom \", \" Lighting \", \" Noise \"]\n",
    "\n",
    "    index = 0\n",
    "    \n",
    "    for prob in range(len(prob_list)):\n",
    "    \n",
    "        prob_list = [0] * len(prob_list)\n",
    "        \n",
    "        prob_list[prob] = 1\n",
    "\n",
    "        zoom_prob = prob_list[0]\n",
    "        noise_prob = prob_list[1]\n",
    "        \n",
    "        aug_list = [flip_prob, zoom_prob, light_prob, noise_prob]\n",
    "        file_name = ''\n",
    "        \n",
    "        for augment in range(len(aug_list)):\n",
    "            \n",
    "            if aug_list[augment] == 1:\n",
    "                \n",
    "                file_name = file_name + str(prob_name[augment])\n",
    "            \n",
    "        print(\"Model augmented with:\", file_name)\n",
    "    \n",
    "    \n",
    "        print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "    \n",
    "        #Training Dataset Creation\n",
    "        training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "        print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "        model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size, epochs = 10)\n",
    "\n",
    "        test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "        model_list.append(model)\n",
    "        aug_names_list.append(file_name)\n",
    "        train_miou_list.append(train_miou[best_epoch-1])\n",
    "        train_loss_list.append(train_loss[best_epoch-1])\n",
    "        valid_miou_list.append(val_miou[best_epoch-1])\n",
    "        valid_loss_list.append(val_loss[best_epoch-1])\n",
    "        test_miou_list.append(test_miou)\n",
    "        test_loss_list.append(test_loss)\n",
    "        learning_rate_list.append(best_learning_rate)\n",
    "        epoch_list.append((best_epoch + 10))\n",
    "\n",
    "        file_path = os.getcwd()+'/models/Merged_Train_Merged_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "        model_list[index].save_weights(file_path)\n",
    "        index += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    #All augmentations\n",
    "    noise_prob = flip_prob = light_prob = zoom_prob = 1\n",
    "    file_name = 'All augments'\n",
    "\n",
    "    print(\"Model augmented with:\", file_name)\n",
    "    print(flip_prob, zoom_prob, light_prob, noise_prob)\n",
    "    \n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "    print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "\n",
    "\n",
    "    model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                activation, dropout, weight_decay, \n",
    "                                                                                                training_dataset, validation_dataset, \n",
    "                                                                                                batch_size, epochs = 10)\n",
    "\n",
    "    test_loss, test_miou =  model.evaluate(test_dataset, verbose = 0)\n",
    "    model_list.append(model)\n",
    "    aug_names_list.append(file_name)\n",
    "    train_miou_list.append(train_miou[best_epoch-1])\n",
    "    train_loss_list.append(train_loss[best_epoch-1])\n",
    "    valid_miou_list.append(val_miou[best_epoch-1])\n",
    "    valid_loss_list.append(val_loss[best_epoch-1])\n",
    "    test_miou_list.append(test_miou)\n",
    "    test_loss_list.append(test_loss)\n",
    "    learning_rate_list.append(best_learning_rate)\n",
    "    epoch_list.append((best_epoch + 10))\n",
    "\n",
    "    file_path = os.getcwd()+'/models/Merged_Train_Merged_Val/augmentations/weights/'+file_name+'_model_weight.weights.h5'\n",
    "    model_list[index].save_weights(file_path)\n",
    "\n",
    "else:\n",
    "    print(\"Augmentations already performed. Skipping execution of cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/Loss_final.jpg\"):\n",
    "    plot_loss_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Augmentations vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/Loss_final.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/Loss_final.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "\n",
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/MIoU_final.jpg\"):\n",
    "    plot_miou_aug(aug_names_list)\n",
    "    plot.xlabel('Augmentations')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Augmentations vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(axis='y')\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/MIoU_final.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/graphs/MIoU_final.jpg\")\n",
    "                       \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/augmentations/results.txt\"):\n",
    "    best_valid_loss = 100\n",
    "    index = 0\n",
    "\n",
    "    while index < len(model_list):\n",
    "        if valid_loss_list[index] < best_valid_loss:\n",
    "            index_of_best_model = index\n",
    "            best_valid_loss = valid_loss_list[index]\n",
    "        index += 1\n",
    "\n",
    "    best_model = model_list[index_of_best_model]\n",
    "    best_augmentation = aug_names_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "    Train_Loss = train_loss_list[index_of_best_model]\n",
    "    Train_MIoU = train_miou_list[index_of_best_model]\n",
    "    Val_Loss = valid_loss_list[index_of_best_model]\n",
    "    Val_MIoU = valid_miou_list[index_of_best_model]\n",
    "    Test_loss = test_loss_list[index_of_best_model]\n",
    "    Test_MIoU = test_miou_list[index_of_best_model]\n",
    "\n",
    "    print(\"Best Augmentation: \",best_augmentation)\n",
    "    print(\"Training Loss: \",Train_Loss)\n",
    "    print(\"Training MIoU: \",Train_MIoU)\n",
    "    print(\"Validation Loss: \",Val_Loss)\n",
    "    print(\"Validation MIoU: \",Val_MIoU)\n",
    "    print(\"Test Loss: \",Test_loss)\n",
    "    print(\"Test MIoU: \",Test_MIoU)\n",
    "\n",
    "    #  Save Best Model Weights\n",
    "    file_path = os.getcwd()+'/models/Merged_Train_Merged_Val/augmentations/best_augmentation_model_weight.weights.h5'\n",
    "    model_list[index_of_best_model].save_weights(file_path)\n",
    "\n",
    "    # Open the file in write mode and write the results\n",
    "    # Saving Results\n",
    "    filename = os.getcwd()+'/models/Merged_Train_Merged_Val/augmentations/results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Augmentation: {best_augmentation}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"Results already stored in file\")\n",
    "    with open(os.getcwd()+'/models/Merged_Train_Merged_Val/augmentations/results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Augmentation'):\n",
    "                best_aug = str(line.split(':')[-1].strip())\n",
    "\n",
    "    print(\"Best Augmentation: \",best_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Evaluation\n",
    "\n",
    "\n",
    "In this section, the previously obtained results are summarized and compared. The following table compares the optimum hyperparameters and combination of augmentations for each model.\n",
    "\n",
    "\n",
    "| Dataset | Training | Validation | Test | Best Batch Size | Best Dropout Rate | Best Weight Decay | Best Augmentations |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 1 | KITTI | CityScape Subset | IKA | 4 | 0.5 | 1e-07 | Flip + Zoom + Noise |\n",
    "| 2 | CityScape Subset | KITTI | IKA | 4 | 0 | 1e-06 | Flip + Zoom |\n",
    "| 3 | Merged | Merged | IKA | 6 | 0.1 | 1e-07 | Lighting |\n",
    "\n",
    "<br>\n",
    "\n",
    "The following table compares the test loss function and MIoU metrics among the best models. The best performing metrics are highlighted. Dataset 1, 2 and 3 are referenced in the previous table.\n",
    "\n",
    "| Dataset | Base Model Test Loss | Base Model Test MIoU | Hyperparameter Tuning Test Loss | Hyperparameter Tuning Test MIoU | Augmentations Test Loss | Augmentations Test MIoU |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 1 | 1.634658 | 0.106426 | 1.448689 | ***0.215391*** | ***1.283515*** | 0.210903 |\n",
    "| 2 | 1.672558 | 0.199039 | ***1.364190*** | ***0.264105*** | 1.449450 | 0.260079 |\n",
    "| 3 | 0.633861 | ***0.478815*** | 0.701467 | 0.421821 | ***0.597180*** | 0.470139 |\n",
    "\n",
    "Dataset 1 shows significant decrease in test loss with both hyperparameter tuning and augmentation models as compared to the base model.. However the test MIoU remain almost the same between hyperparameter tuning and augmentation. The combination of augmentations for which it shows the best performance is horizontal flip, random zoom, and random noise and blur. \n",
    "\n",
    "There is improvement in both test metrics in the model with hyperparameter tuning as compared to the base model. However there was an increase in test loss in the best augmentations model, where the dataset is augmented with horizontal flip and random zoom. This was an anomaly since the validation metrics showed improvements in the augmentation model as compared to the hyperparameters model. The augmented model is further used since it uses a slightly bigger dataset and covers more scenarios due to the augmentations.\n",
    "\n",
    "The models with merged dataset showed the best training metrics out of all the models due to its size and diversity. Comparing among the models of the same dataset, there is no improvement upon hyperparameter tuning. This is probably because the models trained during hyperparameter tuning were limited to 10 epochs, whereas the base model was trained up to 32 epochs with necessary callback functions. Lighting was the best augmentation for this dataset, with the speculation that the size of the merged dataset covered a broad array of scenarios except for night-time/dimly lit scenarios. \n",
    "\n",
    "The best models for each dataset are then trained for as many epochs as they can sustain with the callback functions explained in the earlier sections. The history of the model is illustrated with graph plots of training and validation losses and MIoU at the end of each epoch. The trained models are then applied on random images to predict the corresponding labels. A comparison with the original label can be seen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KITTI Training - CityScape Subset Validation\n",
    "\n",
    "training_image_label_pairs = KITTI_training_image_label_pairs\n",
    "validation_image_label_pairs = CityScape_subset_validation_image_label_pairs\n",
    "test_image_label_pairs = ika_test_image_label_pairs\n",
    "\n",
    "udepth = 5\n",
    "filters1 = 16\n",
    "dropout = 0.5\n",
    "weight_decay = 0.0000001\n",
    "batch_size = 4\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "activation = tf.nn.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/Final_Results.txt\"):\n",
    "    \n",
    "    #Best augmentations\n",
    "    flip_prob = zoom_prob = noise_prob = 1\n",
    "    light_prob = 0\n",
    "    \n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "\n",
    "    #Validation Dataset Creation\n",
    "    validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "    early_stopping_patience = 50\n",
    "    model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size, early_stopping_patience = early_stopping_patience,\n",
    "                                                                                                    reduce_lr_patience = early_stopping_patience*0.4)\n",
    "    #Test Dataset\n",
    "    test_dataset = create_dataset(test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "    \n",
    "    test_loss, test_miou =  model.evaluate(test_dataset, verbose = 1)\n",
    "\n",
    "    total_epochs = (best_epoch + early_stopping_patience)\n",
    "\n",
    "    # Save Model Weights\n",
    "    file_path = 'models/KITTI_Train_CityScape_Val/Final_KITTI_CityScape_model_weight.weights.h5'\n",
    "    model.save_weights(file_path)\n",
    "    \n",
    "    # Store Best Learning Rate in file\n",
    "    Train_Loss = train_loss[best_epoch-1]\n",
    "    Train_MIoU = train_miou[best_epoch-1]\n",
    "    Val_Loss = val_loss[best_epoch-1]\n",
    "    Val_MIoU = val_miou[best_epoch-1]\n",
    "    Test_loss = test_loss\n",
    "    Test_MIoU = test_miou\n",
    "    \n",
    "    filename = os.getcwd()+'/models/KITTI_Train_CityScape_Val/Final_Results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Learning Rate: {best_learning_rate}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        file.write(f\"Total Epochs: {total_epochs}\\n\")\n",
    "        \n",
    "    epoch_list = list(range(1, total_epochs+1))\n",
    "\n",
    "    plot.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot Training Loss\n",
    "    plot.plot(epoch_list, train_loss, marker='o', linestyle='--', color='black', label = 'Training Loss')\n",
    "    plot.yscale('log')\n",
    "    # Plot Validation Loss\n",
    "    plot.plot(epoch_list, val_loss, marker='o', linestyle='--', color='blue', label = 'Validation Loss')\n",
    "    plot.yscale('log')\n",
    "    plot.xlabel('Epochs')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Epochs vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/Epochs_vs_Loss.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "    # Plot Training Loss\n",
    "    plot.plot(epoch_list, train_miou, marker='o', linestyle='--', color='black', label = 'Training MIoU')\n",
    "\n",
    "    # Plot Validation Loss\n",
    "    plot.plot(epoch_list, val_miou, marker='o', linestyle='--', color='blue', label = 'Validation MIoU')\n",
    "\n",
    "    plot.xlabel('Epochs')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Epochs vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/Epochs_vs_MIoU.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Final Model already trained\")\n",
    "    \n",
    "    # Open the file in read mode\n",
    "    file_path = os.getcwd()+\"/models/KITTI_Train_CityScape_Val/Final_Results.txt\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read the entire file content\n",
    "        content = file.read()\n",
    "\n",
    "    # Print the content\n",
    "    print(content)\n",
    "\n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/Epochs_vs_Loss.jpg\") \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "    \n",
    "    img = mpimg.imread(os.getcwd()+\"/models/KITTI_Train_CityScape_Val/Epochs_vs_MIoU.jpg\") \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Model_1 = getModel(input_shape=(368, 1248, 3),\n",
    "                num_classes = num_classes,\n",
    "                udepth = udepth,\n",
    "                filters1 = filters1,\n",
    "                kernel_size = kernel_size,\n",
    "                activation = activation,\n",
    "                batch_norm=True,\n",
    "                dropout = dropout,\n",
    "                l2_weight_decay = weight_decay)\n",
    "with open(os.getcwd()+'/models/KITTI_Train_CityScape_Val/Final_Results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Learning Rate'):\n",
    "                best_learning_rate = float(line.split(':')[-1].strip())\n",
    "Final_Model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_learning_rate),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[SparseMeanIoU(num_classes=num_classes, name=\"MIoU\")])\n",
    "Final_Model_1.load_weights(os.getcwd()+'/models/KITTI_Train_CityScape_Val/Final_KITTI_CityScape_model_weight.weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CityScape Subset Training - KITTI Validation\n",
    "\n",
    "training_image_label_pairs = CityScape_subset_training_image_label_pairs\n",
    "validation_image_label_pairs = KITTI_validation_image_label_pairs\n",
    "test_image_label_pairs = ika_test_image_label_pairs\n",
    "\n",
    "udepth = 5\n",
    "filters1 = 16\n",
    "dropout = 0\n",
    "weight_decay = 0.000001\n",
    "batch_size = 4\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "activation = tf.nn.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/Final_Results.txt\"):\n",
    "    \n",
    "    #Best augmentations\n",
    "    flip_prob = zoom_prob = 1\n",
    "    light_prob = noise_prob = 0\n",
    "    \n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "    print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "    \n",
    "    #Validation Dataset Creation\n",
    "    validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "    early_stopping_patience = 50\n",
    "    model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size, early_stopping_patience = early_stopping_patience,\n",
    "                                                                                                    reduce_lr_patience = early_stopping_patience*0.4)\n",
    "    #Test Dataset\n",
    "    test_dataset = create_dataset(test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "    \n",
    "    test_loss, test_miou =  model.evaluate(test_dataset, verbose = 1)\n",
    "\n",
    "    total_epochs = (best_epoch + early_stopping_patience)\n",
    "\n",
    "    # Save Model Weights\n",
    "    file_path = 'models/CityScape_Train_KITTI_Val/Final_CityScape_KITTI_model_weight.weights.h5'\n",
    "    model.save_weights(file_path)\n",
    "    \n",
    "    # Store Best Learning Rate in file\n",
    "    Train_Loss = train_loss[best_epoch-1]\n",
    "    Train_MIoU = train_miou[best_epoch-1]\n",
    "    Val_Loss = val_loss[best_epoch-1]\n",
    "    Val_MIoU = val_miou[best_epoch-1]\n",
    "    Test_loss = test_loss\n",
    "    Test_MIoU = test_miou\n",
    "    \n",
    "    filename = os.getcwd()+'/models/CityScape_Train_KITTI_Val/Final_Results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Learning Rate: {best_learning_rate}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        file.write(f\"Total Epochs: {total_epochs}\\n\")\n",
    "        \n",
    "    epoch_list = list(range(1, total_epochs+1))\n",
    "\n",
    "    plot.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot Training Loss\n",
    "    plot.plot(epoch_list, train_loss, marker='o', linestyle='--', color='black', label = 'Training Loss')\n",
    "    plot.yscale('log')\n",
    "    # Plot Validation Loss\n",
    "    plot.plot(epoch_list, val_loss, marker='o', linestyle='--', color='blue', label = 'Validation Loss')\n",
    "    plot.yscale('log')\n",
    "    plot.xlabel('Epochs')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Epochs vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/Epochs_vs_Loss.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "    # Plot Training Loss\n",
    "    plot.plot(epoch_list, train_miou, marker='o', linestyle='--', color='black', label = 'Training MIoU')\n",
    "\n",
    "    # Plot Validation Loss\n",
    "    plot.plot(epoch_list, val_miou, marker='o', linestyle='--', color='blue', label = 'Validation MIoU')\n",
    "\n",
    "    plot.xlabel('Epochs')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Epochs vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/Epochs_vs_MIoU.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Final Model already trained\")\n",
    "    \n",
    "    # Open the file in read mode\n",
    "    file_path = os.getcwd()+\"/models/CityScape_Train_KITTI_Val/Final_Results.txt\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read the entire file content\n",
    "        content = file.read()\n",
    "\n",
    "    # Print the content\n",
    "    print(content)\n",
    "\n",
    "    \n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/Epochs_vs_Loss.jpg\") \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "    \n",
    "    img = mpimg.imread(os.getcwd()+\"/models/CityScape_Train_KITTI_Val/Epochs_vs_MIoU.jpg\") \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Model_2 = getModel(input_shape=(368, 1248, 3),\n",
    "                num_classes = num_classes,\n",
    "                udepth = udepth,\n",
    "                filters1 = filters1,\n",
    "                kernel_size = kernel_size,\n",
    "                activation = activation,\n",
    "                batch_norm=True,\n",
    "                dropout = dropout,\n",
    "                l2_weight_decay = weight_decay)\n",
    "with open(os.getcwd()+'/models/CityScape_Train_KITTI_Val/Final_Results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Learning Rate'):\n",
    "                best_learning_rate = float(line.split(':')[-1].strip())\n",
    "Final_Model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_learning_rate),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[SparseMeanIoU(num_classes=num_classes, name=\"MIoU\")])\n",
    "Final_Model_2.load_weights(os.getcwd()+'/models/CityScape_Train_KITTI_Val/Final_CityScape_KITTI_model_weight.weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merged Training - Merged Validation\n",
    "\n",
    "training_image_label_pairs = merged_training_image_label_pairs\n",
    "validation_image_label_pairs = merged_validation_image_label_pairs\n",
    "test_image_label_pairs = ika_test_image_label_pairs\n",
    "\n",
    "udepth = 5\n",
    "filters1 = 16\n",
    "dropout = 0.1\n",
    "weight_decay = 0.0000001\n",
    "batch_size = 6\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "activation = tf.nn.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd()+\"/models/Merged_Train_Merged_Val/Final_Results.txt\"):\n",
    "    \n",
    "    #Best augmentations\n",
    "    flip_prob = zoom_prob = noise_prob = 0\n",
    "    light_prob = 1\n",
    "    \n",
    "    #Training Dataset Creation\n",
    "    training_dataset = create_dataset(training_image_label_pairs, batch_size = batch_size,do_augmentation = True)\n",
    "    print(\"Training Dataset Length:\", tf.data.experimental.cardinality(training_dataset).numpy())\n",
    "    \n",
    "    #Validation Dataset Creation\n",
    "    validation_dataset = create_dataset(validation_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "\n",
    "    early_stopping_patience = 50\n",
    "    model, train_miou, train_loss, val_miou, val_loss, best_epoch, best_learning_rate= CNN_model(num_classes, udepth, filters1, kernel_size, \n",
    "                                                                                                    activation, dropout, weight_decay, \n",
    "                                                                                                    training_dataset, validation_dataset, \n",
    "                                                                                                    batch_size, early_stopping_patience = early_stopping_patience,\n",
    "                                                                                                    reduce_lr_patience = early_stopping_patience*0.4)\n",
    "    #Test Dataset\n",
    "    test_dataset = create_dataset(test_image_label_pairs, batch_size = batch_size,do_augmentation = False)\n",
    "    \n",
    "    test_loss, test_miou =  model.evaluate(test_dataset, verbose = 1)\n",
    "\n",
    "    total_epochs = (best_epoch + early_stopping_patience)\n",
    "\n",
    "    # Save Model Weights\n",
    "    file_path = 'models/Merged_Train_Merged_Val/Final_Merged_model_weight.weights.h5'\n",
    "    model.save_weights(file_path)\n",
    "    \n",
    "    # Store Best Learning Rate in file\n",
    "    Train_Loss = train_loss[best_epoch-1]\n",
    "    Train_MIoU = train_miou[best_epoch-1]\n",
    "    Val_Loss = val_loss[best_epoch-1]\n",
    "    Val_MIoU = val_miou[best_epoch-1]\n",
    "    Test_loss = test_loss\n",
    "    Test_MIoU = test_miou\n",
    "    \n",
    "    filename = os.getcwd()+'/models/Merged_Train_Merged_Val/Final_Results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(f\"Best Learning Rate: {best_learning_rate}\\n\")\n",
    "        file.write(f\"Training Loss: {Train_Loss}\\n\")\n",
    "        file.write(f\"Training MIoU: {Train_MIoU}\\n\")\n",
    "        file.write(f\"Validation Loss: {Val_Loss}\\n\")\n",
    "        file.write(f\"Validation MIoU: {Val_MIoU}\\n\")\n",
    "        file.write(f\"Test Loss: {Test_loss}\\n\")\n",
    "        file.write(f\"Test MIoU: {Test_MIoU}\\n\")\n",
    "        file.write(f\"Total Epochs: {total_epochs}\\n\")\n",
    "        \n",
    "    epoch_list = list(range(1, total_epochs+1))\n",
    "\n",
    "    plot.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot Training Loss\n",
    "    plot.plot(epoch_list, train_loss, marker='o', linestyle='--', color='black', label = 'Training Loss')\n",
    "    plot.yscale('log')\n",
    "    # Plot Validation Loss\n",
    "    plot.plot(epoch_list, val_loss, marker='o', linestyle='--', color='blue', label = 'Validation Loss')\n",
    "    plot.yscale('log')\n",
    "    plot.xlabel('Epochs')\n",
    "    plot.ylabel('Loss')\n",
    "    plot.title('Epochs vs Loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/Epochs_vs_Loss.jpg\")\n",
    "    plot.show()\n",
    "\n",
    "    # Plot Training Loss\n",
    "    plot.plot(epoch_list, train_miou, marker='o', linestyle='--', color='black', label = 'Training MIoU')\n",
    "\n",
    "    # Plot Validation Loss\n",
    "    plot.plot(epoch_list, val_miou, marker='o', linestyle='--', color='blue', label = 'Validation MIoU')\n",
    "\n",
    "    plot.xlabel('Epochs')\n",
    "    plot.ylabel('MIoU')\n",
    "    plot.title('Epochs vs MIoU')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "    plot.savefig(os.getcwd()+\"/models/Merged_Train_Merged_Val/Epochs_vs_MIoU.jpg\")\n",
    "    plot.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Final Model already trained\")\n",
    "    \n",
    "    # Open the file in read mode\n",
    "    file_path = os.getcwd()+\"/models/Merged_Train_Merged_Val/Final_Results.txt\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read the entire file content\n",
    "        content = file.read()\n",
    "\n",
    "    # Print the content\n",
    "    print(content)\n",
    "\n",
    "    \n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/Epochs_vs_Loss.jpg\") \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()\n",
    "    \n",
    "    img = mpimg.imread(os.getcwd()+\"/models/Merged_Train_Merged_Val/Epochs_vs_MIoU.jpg\") \n",
    "    # Display the image\n",
    "    plot.imshow(img)\n",
    "    plot.axis('off')  # Hide axes\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Model_3 = getModel(input_shape=(368, 1248, 3),\n",
    "                num_classes = num_classes,\n",
    "                udepth = udepth,\n",
    "                filters1 = filters1,\n",
    "                kernel_size = kernel_size,\n",
    "                activation = activation,\n",
    "                batch_norm=True,\n",
    "                dropout = dropout,\n",
    "                l2_weight_decay = weight_decay)\n",
    "with open(os.getcwd()+'/models/Merged_Train_Merged_Val/Final_Results.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('Best Learning Rate'):\n",
    "                best_learning_rate = float(line.split(':')[-1].strip())\n",
    "Final_Model_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_learning_rate),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[SparseMeanIoU(num_classes=num_classes, name=\"MIoU\")])\n",
    "Final_Model_3.load_weights(os.getcwd()+'/models/Merged_Train_Merged_Val/Final_Merged_model_weight.weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code taken from ACDC Course with some modifications\n",
    "\n",
    "#Model Inference\n",
    "img_number = random.randint(0, len(test_image_label_pairs)-1)\n",
    "\n",
    "image, label = parse_sample(test_image_label_pairs[img_number][0], test_image_label_pairs[img_number][1])\n",
    "image, label = normalize(image, label)\n",
    "\n",
    "\n",
    "img = tf.image.decode_image(tf.io.read_file(ika_test_image_label_pairs[img_number][0]), channels=3)\n",
    "img = tf.image.resize(img, [368, 1248], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "plot.figure(figsize=(12, 12))\n",
    "plot.imshow(img)\n",
    "plot.title(\"Input Image\")\n",
    "plot.savefig(os.getcwd()+\"/models/image.jpg\")\n",
    "plot.show()\n",
    "\n",
    "\n",
    "rgb_encoding_label = segmentation_map_to_rgb_encoding(npy.squeeze(label), RGB_to_ClassID)\n",
    "\n",
    "plot.figure(figsize=(12, 12))\n",
    "plot.imshow(rgb_encoding_label)\n",
    "plot.title(\"RGB Encoding Label\")\n",
    "plot.savefig(os.getcwd()+\"/models/label.jpg\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add batch dimension\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "probabilities_a = Base_Model_1.predict(image)\n",
    "probabilities_b = Base_Model_2.predict(image)\n",
    "probabilities_c = Base_Model_3.predict(image)\n",
    "\n",
    "probabilities_1 = Final_Model_1.predict(image)\n",
    "probabilities_2 = Final_Model_2.predict(image)\n",
    "probabilities_3 = Final_Model_3.predict(image)\n",
    "\n",
    "# Compute Segmentation Map from One Hot Encoding Vector\n",
    "\n",
    "# compute the segmentation map\n",
    "prediction_a = tf.argmax(probabilities_a, axis=-1)\n",
    "prediction_b = tf.argmax(probabilities_b, axis=-1)\n",
    "prediction_c = tf.argmax(probabilities_c, axis=-1)\n",
    "\n",
    "prediction_1 = tf.argmax(probabilities_1, axis=-1)\n",
    "prediction_2 = tf.argmax(probabilities_2, axis=-1)\n",
    "prediction_3 = tf.argmax(probabilities_3, axis=-1)\n",
    "# get rid of the batch dimension\n",
    "prediction_a = tf.squeeze(prediction_a)\n",
    "prediction_b = tf.squeeze(prediction_b)\n",
    "prediction_c = tf.squeeze(prediction_c)\n",
    "\n",
    "prediction_1 = tf.squeeze(prediction_1)\n",
    "prediction_2 = tf.squeeze(prediction_2)\n",
    "prediction_3 = tf.squeeze(prediction_3)\n",
    "\n",
    "rgb_encoding_a = segmentation_map_to_rgb_encoding(prediction_a, RGB_to_ClassID)\n",
    "rgb_encoding_b = segmentation_map_to_rgb_encoding(prediction_b, RGB_to_ClassID)\n",
    "rgb_encoding_c = segmentation_map_to_rgb_encoding(prediction_c, RGB_to_ClassID)\n",
    "\n",
    "rgb_encoding_1 = segmentation_map_to_rgb_encoding(prediction_1, RGB_to_ClassID)\n",
    "rgb_encoding_2 = segmentation_map_to_rgb_encoding(prediction_2, RGB_to_ClassID)\n",
    "rgb_encoding_3 = segmentation_map_to_rgb_encoding(prediction_3, RGB_to_ClassID)\n",
    "\n",
    "plot.figure(figsize=(12, 12))\n",
    "plot.imshow(rgb_encoding_a)\n",
    "plot.title(\"KITTI-CityScape_Subset Base Model Prediction\")\n",
    "plot.savefig(os.getcwd()+\"/models/KITTI_CityScape_Subset_Base_pred.jpg\")\n",
    "plot.show()\n",
    "\n",
    "plot.figure(figsize=(12, 12))\n",
    "plot.imshow(rgb_encoding_b)\n",
    "plot.title(\"CityScape_Subset-KITTI Base Model Prediction\")\n",
    "plot.savefig(os.getcwd()+\"/models/CityScape_Subset_KITTI_Base_pred.jpg\")\n",
    "plot.show()\n",
    "\n",
    "plot.figure(figsize=(12, 12))\n",
    "plot.imshow(rgb_encoding_c)\n",
    "plot.title(\"Merged-Merged Base Model Prediction\")\n",
    "plot.savefig(os.getcwd()+\"/models/Merged_Merged_Base_pred.jpg\")\n",
    "plot.show()\n",
    "\n",
    "\n",
    "plot.figure(figsize=(12, 12))\n",
    "plot.imshow(rgb_encoding_1)\n",
    "plot.title(\"KITTI-CityScape_Subset Final Model Prediction\")\n",
    "plot.savefig(os.getcwd()+\"/models/KITTI_CityScape_Subset_Final_pred.jpg\")\n",
    "plot.show()\n",
    "\n",
    "plot.figure(figsize=(12, 12))\n",
    "plot.imshow(rgb_encoding_2)\n",
    "plot.title(\"CityScape_Subset-KITTI Final Model Prediction\")\n",
    "plot.savefig(os.getcwd()+\"/models/CityScape_Subset_KITTI_Final_pred.jpg\")\n",
    "plot.show()\n",
    "\n",
    "plot.figure(figsize=(12, 12))\n",
    "plot.imshow(rgb_encoding_3)\n",
    "plot.title(\"Merged-Merged Final Model Prediction\")\n",
    "plot.savefig(os.getcwd()+\"/models/Merged_Merged_Final_pred.jpg\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "\n",
    "\n",
    "The concept of semantic image segmentation and its dependence on domain adaptation were discussed. To investigate this, a methodology was designed which included dataset selection, data processing, and training of CNN models with select hyperparameters and augmentations. The experiments involved the examination of comparative models to derive the optimum recommendations. A final model is suggested based on these findings and recommendations.\n",
    "\n",
    "Hyperparameter tuning and data augmentations were shown to improve the training models as compared to the base model. The size of the dataset had a major effect, with the models trained with the larger dataset showing very good performance. The merged dataset also contained from select cities outside of Germany, which would have improved the model's diversity. The fact that it contained data from the same city as the target domain also helped with the performance. Augmentations also showed improve performances, but was inconsistent. A better understanding of the performance of these models can be obtained when evaluated with a larger and more diverse target domain. For larger datasets it is recommended to augment a part of the dataset, rather than add augmented data to the original dataset.\n",
    "\n",
    "The investigations on data augmentations in this project was one-dimensional. There is scope for a more thorough experiment involving multiple probabilities and a finer range of augmentation values. It can also be deduced that the model shows drastic improvement when parts of the target data are already integrated into the source data. A more extensive study on this is viable in further research studies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **References**\n",
    "\n",
    "\n",
    "| # | Year | Authors | Title |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | 2018 | H.A. Alhaija, S.K. Mustikovela, L. Mescheder, A. Geiger, C. Rother | [Augmented Reality Meets Computer Vision: Efficient Data Generation for Urban Driving Scenes](https://www.cvlibs.net/publications/Alhaija2018IJCV.pdf) |\n",
    "| 2 | 2016 | M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, B. Schiele | [The Cityscapes Dataset for Semantic Urban Scene Understanding](https://www.cityscapes-dataset.com/wordpress/wp-content/papercite-data/pdf/cordts2016cityscapes.pdf) |\n",
    "| 3 | 2015 | J. Long, E. Shelhamer, T. Darrell | [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1411.4038) |\n",
    "| 4 | 2017 | L.C. Chen, G. Papandreou, F. Schroff, H. Adam | [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587) | \n",
    "| 5 | 2015 | O. Ronneberger, P. Fischer, T. Brox | [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597) |\n",
    "| 6 | 2021 | G. Csurka, R. Volpi, B. Chidlovskii | [Unsupervised Domain Adaptation for Semantic Image Segmentation: a Comprehensive Survey](https://arxiv.org/abs/2112.03241) |\n",
    "| 7 | 2017 | Y. Zhang, P. David, B. Gong | [Curriculum Domain Adaptation for Semantic Segmentation of Urban Scenes](https://arxiv.org/abs/1707.09465) |\n",
    "| 8 | 2018 | Y. Guo, Y. Liu, T. Georgiou, M. S. Lew | [A review of semantic segmentation using deep neural networks](https://link.springer.com/article/10.1007/s13735-017-0141-z) |\n",
    "| 9 | 2019 | A. Kirillov, K. He, R. Girshick, C. Rother, P. Dollár | [Panoptic Segmentation](https://arxiv.org/abs/1801.00868) |\n",
    "| 10 | 2015 | W. Liu, A. Rabinovich, A. C. Berg | [ParseNet: Looking Wider to See Better](https://arxiv.org/abs/1506.04579) |\n",
    "| 11 | 2016 | Ö. Çiçek, A. Abdulkadir, S.S. Lienkamp, T. Brox, O. Ronneberger | [3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation](https://arxiv.org/abs/1606.06650) |\n",
    "| 12 | 2018 | O. Oktay, J. Schlemper, L.L. Folgoc, M. Lee, M. Heinrich, K. Misawa, K. Mori, S. McDonagh, N. Y. Hammerla, B. Kainz, B. Glocker, D. Rueckert | [Attention U-Net: Learning Where to Look for the Pancreas](https://arxiv.org/abs/1804.03999) |\n",
    "| 13 | 2018 | H. Caesar, J. Uijlings, V. Ferrari | [COCO-Stuff: Thing and Stuff Classes in Context](https://arxiv.org/abs/1612.03716) |\n",
    "| 14 | 2016 | G. Ros, L. Sellart, J. Materzynska, D. Vazquez, A.M. Lopez | [The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes](https://ieeexplore.ieee.org/document/7780721) |\n",
    "| 15 | 2016 | S.R. Richter, V. Vineet, S. Roth, V. Koltun | [Playing for Data: Ground Truth from Computer Games](https://arxiv.org/abs/1608.02192) |\n",
    "| 16 | 2016 | J. Hoffman, D. Wang, F. Yu, T. Darrell | [FCNs in the Wild: Pixel-level Adversarial and Constraint-based Adaptation](https://arxiv.org/abs/1612.02649) |\n",
    "| 17 | 2020 | Y. Tsai, W. Hung, S. Schulter, K. Sohn, M. Yang, M. Chandraker | [Learning to Adapt Structured Output Space for Semantic Segmentation](https://arxiv.org/abs/1802.10349) |\n",
    "| 18 | 2017 | J. Tobin, R. Fong, A. Ray, J. Schneider, W. Zaremba, P. Abbeel | [Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World](https://arxiv.org/abs/1703.06907) |\n",
    "| 19 | 2020 | H. Li, Y. Wang, R. Wan, S. Wang, T. Li, A.C. Kot | [Domain Generalization for Medical Imaging Classification with Linear-Dependency Regularization](https://arxiv.org/pdf/2009.12829) |\n",
    "| 20 | 2017 | J. Zhu, T. Park, P. Isola, A.A. Efros | [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593) |\n",
    "| 21 | 2018 | G. French, M. Mackiewicz, M. Fisher | [Self-ensembling for visual domain adaptation](https://arxiv.org/abs/1706.05208) |"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
